{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPz57IZL3XGWhKgL70bgUtm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OQlCqHTP9N4F","executionInfo":{"status":"ok","timestamp":1734030402337,"user_tz":300,"elapsed":22865,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}},"outputId":"b9071f8a-e213-45b0-bf85-2f39130f0ae7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["Autoregressive Linear Regression on just Blood Glucose"],"metadata":{"id":"tqnTDSRvEHjU"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import train_test_split\n","\n","# Load the data\n","file_path = '/content/drive/My Drive/Thesis/Subject2.xlsx'\n","cgm_data = pd.read_excel(file_path, sheet_name='CGM')"],"metadata":{"id":"ud1OmyUu2v7P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Preprocess - Round to nearest 5 minutes\n","cgm_data['date'] = pd.to_datetime(cgm_data['date']).dt.round('5min')\n","\n","# Filter out rows where mg/dl is > 400 or missing values\n","cgm_data = cgm_data[cgm_data['mg/dl'] <= 400].dropna(subset=['mg/dl'])\n","\n","# Drop duplicates and sort\n","cgm_data = cgm_data.drop_duplicates(subset='date').reset_index(drop=True)\n","cgm_data = cgm_data.sort_values(by='date').reset_index(drop=True)"],"metadata":{"id":"douYzyaW2xjy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Generate AR Features (using past 12 readings as input)\n","num_lags = 12 # Using the past 12 values\n","for lag in range(1, num_lags + 1):\n","    cgm_data[f'lag_{lag}'] = cgm_data['mg/dl'].shift(lag)\n","\n","cgm_data = cgm_data.dropna().reset_index(drop=True)"],"metadata":{"id":"CRxaWkzv2x6u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split into train/test (80% train, 20% test by time order)\n","train_size = int(len(cgm_data) * 0.8)\n","train_data = cgm_data[:train_size]\n","test_data = cgm_data[train_size:]"],"metadata":{"id":"OkoX5i1J2002"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define function to train and evaluate for different time steps\n","def train_ar_model(data, target_step):\n","    # Prepare inputs (X) and target (y)\n","    X = data[[f'lag_{i}' for i in range(1, num_lags + 1)]].values\n","    y = data['mg/dl'].shift(-target_step).dropna().values\n","    X = X[:len(y)]  # Align lengths\n","\n","    # Split into train/test\n","    X_train, X_test = X[:train_size], X[train_size:]\n","    y_train, y_test = y[:train_size], y[train_size:]\n","\n","    # Train the model\n","    model = LinearRegression()\n","    model.fit(X_train, y_train)\n","\n","    # Make predictions\n","    y_pred = model.predict(X_test)\n","\n","    # Calculate performance metric (RMSE)\n","    rmse = np.sqrt(mean_squared_error(y_test, y_pred))  # Use np.sqrt on MSE\n","\n","    # Display the coefficients\n","    coefficients = model.coef_\n","    intercept = model.intercept_\n","\n","    print(\"Linear Regression Coefficients (lags):\")\n","    for i, coef in enumerate(coefficients, start=1):\n","      print(f\"Lag {i}: {coef:.4f}\")\n","    print(f\"Intercept: {intercept:.4f}\")\n","\n","    return model, rmse"],"metadata":{"id":"x97E22Mm22Zs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train models for different time step targets and evaluate\n","time_steps = [3, 6, 9, 12]  # Corresponding to 15, 30, 45, 60 minutes\n","results = {}\n","\n","for step in time_steps:\n","    model, rmse = train_ar_model(cgm_data, step)\n","    results[f'{step*5} min ahead'] = {'Model': model, 'RMSE': rmse}\n","    print(f\"Time step {step} (predicting {step*5} minutes ahead) - RMSE: {rmse:.4f}\")\n","\n","# Results dictionary now contains trained models and RMSE for each time target"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0wp2DlsI24Qc","executionInfo":{"status":"ok","timestamp":1734030434533,"user_tz":300,"elapsed":1034,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}},"outputId":"c7687794-a9ef-4e17-b14b-c017548a2961"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Linear Regression Coefficients (lags):\n","Lag 1: 2.2039\n","Lag 2: -0.8506\n","Lag 3: -0.3189\n","Lag 4: -0.0710\n","Lag 5: -0.0354\n","Lag 6: 0.0094\n","Lag 7: -0.0061\n","Lag 8: -0.0108\n","Lag 9: 0.0053\n","Lag 10: -0.0108\n","Lag 11: -0.0157\n","Lag 12: 0.0198\n","Intercept: 14.3989\n","Time step 3 (predicting 15 minutes ahead) - RMSE: 23.9630\n","Linear Regression Coefficients (lags):\n","Lag 1: 2.4234\n","Lag 2: -1.0521\n","Lag 3: -0.3918\n","Lag 4: -0.0928\n","Lag 5: -0.0335\n","Lag 6: 0.0040\n","Lag 7: -0.0182\n","Lag 8: -0.0187\n","Lag 9: 0.0111\n","Lag 10: -0.0103\n","Lag 11: -0.0243\n","Lag 12: 0.0333\n","Intercept: 30.2365\n","Time step 6 (predicting 30 minutes ahead) - RMSE: 37.6561\n","Linear Regression Coefficients (lags):\n","Lag 1: 2.3830\n","Lag 2: -1.0778\n","Lag 3: -0.4079\n","Lag 4: -0.1061\n","Lag 5: -0.0403\n","Lag 6: 0.0080\n","Lag 7: -0.0152\n","Lag 8: -0.0200\n","Lag 9: 0.0065\n","Lag 10: -0.0114\n","Lag 11: -0.0261\n","Lag 12: 0.0444\n","Intercept: 46.8187\n","Time step 9 (predicting 45 minutes ahead) - RMSE: 48.2410\n","Linear Regression Coefficients (lags):\n","Lag 1: 2.2189\n","Lag 2: -1.0377\n","Lag 3: -0.3853\n","Lag 4: -0.0987\n","Lag 5: -0.0397\n","Lag 6: 0.0027\n","Lag 7: -0.0150\n","Lag 8: -0.0192\n","Lag 9: 0.0091\n","Lag 10: -0.0056\n","Lag 11: -0.0270\n","Lag 12: 0.0452\n","Intercept: 62.8093\n","Time step 12 (predicting 60 minutes ahead) - RMSE: 56.0313\n"]}]},{"cell_type":"markdown","source":["ARX Model with Blood Glucose and Bolus Data"],"metadata":{"id":"g3a743rVoLM7"}},{"cell_type":"code","source":["# Load Bolus data\n","bolus_data = pd.read_excel(file_path, sheet_name='Bolus')\n","\n","# Preprocess Bolus data - Round to nearest 5 minutes and fill missing values with 0\n","bolus_data['date'] = pd.to_datetime(bolus_data['date']).dt.round('5min')\n","bolus_data = bolus_data.fillna(0)  # Set missing values to 0\n","\n","# Merge Bolus data with CGM data on date\n","merged_data = pd.merge(cgm_data, bolus_data, on='date', how='left').fillna(0)  # Fill missing values after merge\n","\n","# Generate lag features for Bolus variables\n","bolus_vars = ['normal', 'carbInput', 'insulinCarbRatio', 'bgInput', 'recommended.carb', 'recommended.net',\n","              'recommended.correction', 'insulinSensitivityFactor', 'targetBloodGlucose', 'insulinOnBoard']\n","\n","for var in bolus_vars:\n","    for lag in range(1, num_lags + 1):\n","        merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","\n","# Drop rows with NaNs introduced by shifting\n","merged_data = merged_data.dropna().reset_index(drop=True)\n","\n","# Update train/test split based on merged data\n","train_data = merged_data[:train_size]\n","test_data = merged_data[train_size:]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Jt4GA81BcX0","executionInfo":{"status":"ok","timestamp":1734030580598,"user_tz":300,"elapsed":2545,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}},"outputId":"737206a1-b6da-414f-af5a-25e3c7a1f9d2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-9-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-9-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-9-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-9-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-9-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-9-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-9-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-9-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-9-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-9-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-9-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-9-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-9-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-9-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-9-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-9-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-9-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-9-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-9-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-9-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-9-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-9-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-9-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-9-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n"]}]},{"cell_type":"code","source":["# Modify train_ar_model function to include all lagged features\n","def train_arx_model(data, target_step):\n","    # Prepare inputs (X) - using lag features from both mg/dl and Bolus data\n","    lag_columns = [f'lag_{i}' for i in range(1, num_lags + 1)] + \\\n","                  [f'{var}_lag_{i}' for var in bolus_vars for i in range(1, num_lags + 1)]\n","    X = data[lag_columns].values\n","    y = data['mg/dl'].shift(-target_step).dropna().values\n","    X = X[:len(y)]  # Align lengths\n","\n","    # Split into train/test\n","    X_train, X_test = X[:train_size], X[train_size:]\n","    y_train, y_test = y[:train_size], y[train_size:]\n","\n","    # Train the model\n","    model = LinearRegression()\n","    model.fit(X_train, y_train)\n","\n","    # Make predictions\n","    y_pred = model.predict(X_test)\n","\n","    # Calculate performance metric (RMSE)\n","    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","\n","    # Extract coefficients and intercept\n","    coefficients = model.coef_\n","    intercept = model.intercept_\n","\n","    # Display the coefficients\n","    print(\"Linear Regression Coefficients (ARX Model):\")\n","    feature_names = merged_data.drop(columns=['date', 'mg/dl']).columns\n","    for feature, coef in zip(feature_names, coefficients):\n","      print(f\"{feature}: {coef:.4f}\")\n","    print(f\"Intercept: {intercept:.4f}\")\n","\n","    return model, rmse"],"metadata":{"id":"ZAZtpnsdBmZ_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train ARX models for different time steps and evaluate\n","results_arx = {}\n","for step in time_steps:\n","    model, rmse = train_arx_model(merged_data, step)\n","    results_arx[f'{step*5} min ahead'] = {'Model': model, 'RMSE': rmse}\n","    print(f\"Time step {step} (predicting {step*5} minutes ahead) - ARX RMSE: {rmse:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5LG4pUQsB1R-","executionInfo":{"status":"ok","timestamp":1734030594975,"user_tz":300,"elapsed":8712,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}},"outputId":"41c5b4b9-0c8d-4dd9-df21-9af9fbb87a6e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Linear Regression Coefficients (ARX Model):\n","lag_1: 2.2038\n","lag_2: -0.8505\n","lag_3: -0.3188\n","lag_4: -0.0710\n","lag_5: -0.0354\n","lag_6: 0.0094\n","lag_7: -0.0061\n","lag_8: -0.0108\n","lag_9: 0.0054\n","lag_10: -0.0108\n","lag_11: -0.0157\n","lag_12: 0.0197\n","normal: 0.0000\n","carbInput: 0.0000\n","insulinCarbRatio: 0.0000\n","bgInput: 0.0000\n","recommended.carb: 0.0000\n","recommended.net: 0.0000\n","recommended.correction: 0.0000\n","insulinSensitivityFactor: 0.0000\n","targetBloodGlucose: 0.0000\n","insulinOnBoard: 0.0000\n","normal_lag_1: 0.0000\n","normal_lag_2: 0.0000\n","normal_lag_3: 0.0000\n","normal_lag_4: 0.0000\n","normal_lag_5: 0.0000\n","normal_lag_6: 0.0000\n","normal_lag_7: 0.0000\n","normal_lag_8: 0.0000\n","normal_lag_9: 0.0000\n","normal_lag_10: 0.0000\n","normal_lag_11: 0.0000\n","normal_lag_12: 0.0000\n","carbInput_lag_1: 0.0000\n","carbInput_lag_2: 0.0000\n","carbInput_lag_3: 0.0000\n","carbInput_lag_4: 0.0000\n","carbInput_lag_5: 0.0000\n","carbInput_lag_6: 0.0000\n","carbInput_lag_7: 0.0000\n","carbInput_lag_8: 0.0000\n","carbInput_lag_9: 0.0000\n","carbInput_lag_10: 0.0000\n","carbInput_lag_11: 0.0000\n","carbInput_lag_12: 0.0000\n","insulinCarbRatio_lag_1: 0.0000\n","insulinCarbRatio_lag_2: 0.0000\n","insulinCarbRatio_lag_3: 0.0000\n","insulinCarbRatio_lag_4: 0.0000\n","insulinCarbRatio_lag_5: 0.0000\n","insulinCarbRatio_lag_6: 0.0000\n","insulinCarbRatio_lag_7: 0.0000\n","insulinCarbRatio_lag_8: 0.0000\n","insulinCarbRatio_lag_9: 0.0000\n","insulinCarbRatio_lag_10: 0.0000\n","insulinCarbRatio_lag_11: 0.0000\n","insulinCarbRatio_lag_12: 0.0000\n","bgInput_lag_1: 0.0000\n","bgInput_lag_2: 0.0000\n","bgInput_lag_3: 0.0000\n","bgInput_lag_4: 0.0000\n","bgInput_lag_5: 0.0000\n","bgInput_lag_6: 0.0000\n","bgInput_lag_7: 0.0000\n","bgInput_lag_8: 0.0000\n","bgInput_lag_9: 0.0000\n","bgInput_lag_10: 0.0000\n","bgInput_lag_11: 0.0000\n","bgInput_lag_12: 0.0000\n","recommended.carb_lag_1: 0.0000\n","recommended.carb_lag_2: 0.0000\n","recommended.carb_lag_3: 0.0000\n","recommended.carb_lag_4: 0.0000\n","recommended.carb_lag_5: 0.0000\n","recommended.carb_lag_6: 0.0000\n","recommended.carb_lag_7: 0.0000\n","recommended.carb_lag_8: 0.0000\n","recommended.carb_lag_9: 0.0000\n","recommended.carb_lag_10: 0.0000\n","recommended.carb_lag_11: 0.0000\n","recommended.carb_lag_12: 0.0000\n","recommended.net_lag_1: 0.0000\n","recommended.net_lag_2: 0.0000\n","recommended.net_lag_3: 0.0000\n","recommended.net_lag_4: 0.0000\n","recommended.net_lag_5: 0.0000\n","recommended.net_lag_6: 0.0000\n","recommended.net_lag_7: 0.0000\n","recommended.net_lag_8: 0.0000\n","recommended.net_lag_9: 0.0000\n","recommended.net_lag_10: 0.0000\n","recommended.net_lag_11: 0.0000\n","recommended.net_lag_12: 0.0000\n","recommended.correction_lag_1: 0.0000\n","recommended.correction_lag_2: 0.0000\n","recommended.correction_lag_3: 0.0000\n","recommended.correction_lag_4: 0.0000\n","recommended.correction_lag_5: 0.0000\n","recommended.correction_lag_6: 0.0000\n","recommended.correction_lag_7: 0.0000\n","recommended.correction_lag_8: 0.0000\n","recommended.correction_lag_9: 0.0000\n","recommended.correction_lag_10: 0.0000\n","recommended.correction_lag_11: 0.0000\n","recommended.correction_lag_12: 0.0000\n","insulinSensitivityFactor_lag_1: 0.0000\n","insulinSensitivityFactor_lag_2: 0.0000\n","insulinSensitivityFactor_lag_3: 0.0000\n","insulinSensitivityFactor_lag_4: 0.0000\n","insulinSensitivityFactor_lag_5: 0.0000\n","insulinSensitivityFactor_lag_6: 0.0000\n","insulinSensitivityFactor_lag_7: 0.0000\n","insulinSensitivityFactor_lag_8: 0.0000\n","insulinSensitivityFactor_lag_9: 0.0000\n","insulinSensitivityFactor_lag_10: 0.0000\n","insulinSensitivityFactor_lag_11: 0.0000\n","insulinSensitivityFactor_lag_12: 0.0000\n","targetBloodGlucose_lag_1: 0.0000\n","targetBloodGlucose_lag_2: 0.0000\n","targetBloodGlucose_lag_3: 0.0000\n","targetBloodGlucose_lag_4: 0.0000\n","targetBloodGlucose_lag_5: 0.0000\n","targetBloodGlucose_lag_6: 0.0000\n","targetBloodGlucose_lag_7: 0.0000\n","targetBloodGlucose_lag_8: 0.0000\n","targetBloodGlucose_lag_9: 0.0000\n","targetBloodGlucose_lag_10: 0.0000\n","targetBloodGlucose_lag_11: 0.0000\n","targetBloodGlucose_lag_12: 0.0000\n","insulinOnBoard_lag_1: 0.0000\n","insulinOnBoard_lag_2: 0.0000\n","Intercept: 14.3993\n","Time step 3 (predicting 15 minutes ahead) - ARX RMSE: 23.9623\n","Linear Regression Coefficients (ARX Model):\n","lag_1: 2.4233\n","lag_2: -1.0519\n","lag_3: -0.3917\n","lag_4: -0.0928\n","lag_5: -0.0335\n","lag_6: 0.0040\n","lag_7: -0.0182\n","lag_8: -0.0187\n","lag_9: 0.0111\n","lag_10: -0.0102\n","lag_11: -0.0242\n","lag_12: 0.0331\n","normal: 0.0000\n","carbInput: 0.0000\n","insulinCarbRatio: 0.0000\n","bgInput: 0.0000\n","recommended.carb: 0.0000\n","recommended.net: 0.0000\n","recommended.correction: 0.0000\n","insulinSensitivityFactor: 0.0000\n","targetBloodGlucose: 0.0000\n","insulinOnBoard: 0.0000\n","normal_lag_1: 0.0000\n","normal_lag_2: 0.0000\n","normal_lag_3: 0.0000\n","normal_lag_4: 0.0000\n","normal_lag_5: 0.0000\n","normal_lag_6: 0.0000\n","normal_lag_7: 0.0000\n","normal_lag_8: 0.0000\n","normal_lag_9: 0.0000\n","normal_lag_10: 0.0000\n","normal_lag_11: 0.0000\n","normal_lag_12: 0.0000\n","carbInput_lag_1: 0.0000\n","carbInput_lag_2: 0.0000\n","carbInput_lag_3: 0.0000\n","carbInput_lag_4: 0.0000\n","carbInput_lag_5: 0.0000\n","carbInput_lag_6: 0.0000\n","carbInput_lag_7: 0.0000\n","carbInput_lag_8: 0.0000\n","carbInput_lag_9: 0.0000\n","carbInput_lag_10: 0.0000\n","carbInput_lag_11: 0.0000\n","carbInput_lag_12: 0.0000\n","insulinCarbRatio_lag_1: 0.0000\n","insulinCarbRatio_lag_2: 0.0000\n","insulinCarbRatio_lag_3: 0.0000\n","insulinCarbRatio_lag_4: 0.0000\n","insulinCarbRatio_lag_5: 0.0000\n","insulinCarbRatio_lag_6: 0.0000\n","insulinCarbRatio_lag_7: 0.0000\n","insulinCarbRatio_lag_8: 0.0000\n","insulinCarbRatio_lag_9: 0.0000\n","insulinCarbRatio_lag_10: 0.0000\n","insulinCarbRatio_lag_11: 0.0000\n","insulinCarbRatio_lag_12: 0.0000\n","bgInput_lag_1: 0.0000\n","bgInput_lag_2: 0.0000\n","bgInput_lag_3: 0.0000\n","bgInput_lag_4: 0.0000\n","bgInput_lag_5: 0.0000\n","bgInput_lag_6: 0.0000\n","bgInput_lag_7: 0.0000\n","bgInput_lag_8: 0.0000\n","bgInput_lag_9: 0.0000\n","bgInput_lag_10: 0.0000\n","bgInput_lag_11: 0.0000\n","bgInput_lag_12: 0.0000\n","recommended.carb_lag_1: 0.0000\n","recommended.carb_lag_2: 0.0000\n","recommended.carb_lag_3: 0.0000\n","recommended.carb_lag_4: 0.0000\n","recommended.carb_lag_5: 0.0000\n","recommended.carb_lag_6: 0.0000\n","recommended.carb_lag_7: 0.0000\n","recommended.carb_lag_8: 0.0000\n","recommended.carb_lag_9: 0.0000\n","recommended.carb_lag_10: 0.0000\n","recommended.carb_lag_11: 0.0000\n","recommended.carb_lag_12: 0.0000\n","recommended.net_lag_1: 0.0000\n","recommended.net_lag_2: 0.0000\n","recommended.net_lag_3: 0.0000\n","recommended.net_lag_4: 0.0000\n","recommended.net_lag_5: 0.0000\n","recommended.net_lag_6: 0.0000\n","recommended.net_lag_7: 0.0000\n","recommended.net_lag_8: 0.0000\n","recommended.net_lag_9: 0.0000\n","recommended.net_lag_10: 0.0000\n","recommended.net_lag_11: 0.0000\n","recommended.net_lag_12: 0.0000\n","recommended.correction_lag_1: 0.0000\n","recommended.correction_lag_2: 0.0000\n","recommended.correction_lag_3: 0.0000\n","recommended.correction_lag_4: 0.0000\n","recommended.correction_lag_5: 0.0000\n","recommended.correction_lag_6: 0.0000\n","recommended.correction_lag_7: 0.0000\n","recommended.correction_lag_8: 0.0000\n","recommended.correction_lag_9: 0.0000\n","recommended.correction_lag_10: 0.0000\n","recommended.correction_lag_11: 0.0000\n","recommended.correction_lag_12: 0.0000\n","insulinSensitivityFactor_lag_1: 0.0000\n","insulinSensitivityFactor_lag_2: 0.0000\n","insulinSensitivityFactor_lag_3: 0.0000\n","insulinSensitivityFactor_lag_4: 0.0000\n","insulinSensitivityFactor_lag_5: 0.0000\n","insulinSensitivityFactor_lag_6: 0.0000\n","insulinSensitivityFactor_lag_7: 0.0000\n","insulinSensitivityFactor_lag_8: 0.0000\n","insulinSensitivityFactor_lag_9: 0.0000\n","insulinSensitivityFactor_lag_10: 0.0000\n","insulinSensitivityFactor_lag_11: 0.0000\n","insulinSensitivityFactor_lag_12: 0.0000\n","targetBloodGlucose_lag_1: 0.0000\n","targetBloodGlucose_lag_2: 0.0000\n","targetBloodGlucose_lag_3: 0.0000\n","targetBloodGlucose_lag_4: 0.0000\n","targetBloodGlucose_lag_5: 0.0000\n","targetBloodGlucose_lag_6: 0.0000\n","targetBloodGlucose_lag_7: 0.0000\n","targetBloodGlucose_lag_8: 0.0000\n","targetBloodGlucose_lag_9: 0.0000\n","targetBloodGlucose_lag_10: 0.0000\n","targetBloodGlucose_lag_11: 0.0000\n","targetBloodGlucose_lag_12: 0.0000\n","insulinOnBoard_lag_1: 0.0000\n","insulinOnBoard_lag_2: 0.0000\n","Intercept: 30.2381\n","Time step 6 (predicting 30 minutes ahead) - ARX RMSE: 37.6558\n","Linear Regression Coefficients (ARX Model):\n","lag_1: 2.3830\n","lag_2: -1.0776\n","lag_3: -0.4079\n","lag_4: -0.1061\n","lag_5: -0.0403\n","lag_6: 0.0080\n","lag_7: -0.0152\n","lag_8: -0.0200\n","lag_9: 0.0065\n","lag_10: -0.0113\n","lag_11: -0.0259\n","lag_12: 0.0441\n","normal: 0.0000\n","carbInput: 0.0000\n","insulinCarbRatio: 0.0000\n","bgInput: 0.0000\n","recommended.carb: 0.0000\n","recommended.net: 0.0000\n","recommended.correction: 0.0000\n","insulinSensitivityFactor: 0.0000\n","targetBloodGlucose: 0.0000\n","insulinOnBoard: 0.0000\n","normal_lag_1: 0.0000\n","normal_lag_2: 0.0000\n","normal_lag_3: 0.0000\n","normal_lag_4: 0.0000\n","normal_lag_5: 0.0000\n","normal_lag_6: 0.0000\n","normal_lag_7: 0.0000\n","normal_lag_8: 0.0000\n","normal_lag_9: 0.0000\n","normal_lag_10: 0.0000\n","normal_lag_11: 0.0000\n","normal_lag_12: 0.0000\n","carbInput_lag_1: 0.0000\n","carbInput_lag_2: 0.0000\n","carbInput_lag_3: 0.0000\n","carbInput_lag_4: 0.0000\n","carbInput_lag_5: 0.0000\n","carbInput_lag_6: 0.0000\n","carbInput_lag_7: 0.0000\n","carbInput_lag_8: 0.0000\n","carbInput_lag_9: 0.0000\n","carbInput_lag_10: 0.0000\n","carbInput_lag_11: 0.0000\n","carbInput_lag_12: 0.0000\n","insulinCarbRatio_lag_1: 0.0000\n","insulinCarbRatio_lag_2: 0.0000\n","insulinCarbRatio_lag_3: 0.0000\n","insulinCarbRatio_lag_4: 0.0000\n","insulinCarbRatio_lag_5: 0.0000\n","insulinCarbRatio_lag_6: 0.0000\n","insulinCarbRatio_lag_7: 0.0000\n","insulinCarbRatio_lag_8: 0.0000\n","insulinCarbRatio_lag_9: 0.0000\n","insulinCarbRatio_lag_10: 0.0000\n","insulinCarbRatio_lag_11: 0.0000\n","insulinCarbRatio_lag_12: 0.0000\n","bgInput_lag_1: 0.0000\n","bgInput_lag_2: 0.0000\n","bgInput_lag_3: 0.0000\n","bgInput_lag_4: 0.0000\n","bgInput_lag_5: 0.0000\n","bgInput_lag_6: 0.0000\n","bgInput_lag_7: 0.0000\n","bgInput_lag_8: 0.0000\n","bgInput_lag_9: 0.0000\n","bgInput_lag_10: 0.0000\n","bgInput_lag_11: 0.0000\n","bgInput_lag_12: 0.0000\n","recommended.carb_lag_1: 0.0000\n","recommended.carb_lag_2: 0.0000\n","recommended.carb_lag_3: 0.0000\n","recommended.carb_lag_4: 0.0000\n","recommended.carb_lag_5: 0.0000\n","recommended.carb_lag_6: 0.0000\n","recommended.carb_lag_7: 0.0000\n","recommended.carb_lag_8: 0.0000\n","recommended.carb_lag_9: 0.0000\n","recommended.carb_lag_10: 0.0000\n","recommended.carb_lag_11: 0.0000\n","recommended.carb_lag_12: 0.0000\n","recommended.net_lag_1: 0.0000\n","recommended.net_lag_2: 0.0000\n","recommended.net_lag_3: 0.0000\n","recommended.net_lag_4: 0.0000\n","recommended.net_lag_5: 0.0000\n","recommended.net_lag_6: 0.0000\n","recommended.net_lag_7: 0.0000\n","recommended.net_lag_8: 0.0000\n","recommended.net_lag_9: 0.0000\n","recommended.net_lag_10: 0.0000\n","recommended.net_lag_11: 0.0000\n","recommended.net_lag_12: 0.0000\n","recommended.correction_lag_1: 0.0000\n","recommended.correction_lag_2: 0.0000\n","recommended.correction_lag_3: 0.0000\n","recommended.correction_lag_4: 0.0000\n","recommended.correction_lag_5: 0.0000\n","recommended.correction_lag_6: 0.0000\n","recommended.correction_lag_7: 0.0000\n","recommended.correction_lag_8: 0.0000\n","recommended.correction_lag_9: 0.0000\n","recommended.correction_lag_10: 0.0000\n","recommended.correction_lag_11: 0.0000\n","recommended.correction_lag_12: 0.0000\n","insulinSensitivityFactor_lag_1: 0.0000\n","insulinSensitivityFactor_lag_2: 0.0000\n","insulinSensitivityFactor_lag_3: 0.0000\n","insulinSensitivityFactor_lag_4: 0.0000\n","insulinSensitivityFactor_lag_5: 0.0000\n","insulinSensitivityFactor_lag_6: 0.0000\n","insulinSensitivityFactor_lag_7: 0.0000\n","insulinSensitivityFactor_lag_8: 0.0000\n","insulinSensitivityFactor_lag_9: 0.0000\n","insulinSensitivityFactor_lag_10: 0.0000\n","insulinSensitivityFactor_lag_11: 0.0000\n","insulinSensitivityFactor_lag_12: 0.0000\n","targetBloodGlucose_lag_1: 0.0000\n","targetBloodGlucose_lag_2: 0.0000\n","targetBloodGlucose_lag_3: 0.0000\n","targetBloodGlucose_lag_4: 0.0000\n","targetBloodGlucose_lag_5: 0.0000\n","targetBloodGlucose_lag_6: 0.0000\n","targetBloodGlucose_lag_7: 0.0000\n","targetBloodGlucose_lag_8: 0.0000\n","targetBloodGlucose_lag_9: 0.0000\n","targetBloodGlucose_lag_10: 0.0000\n","targetBloodGlucose_lag_11: 0.0000\n","targetBloodGlucose_lag_12: 0.0000\n","insulinOnBoard_lag_1: 0.0000\n","insulinOnBoard_lag_2: 0.0000\n","Intercept: 46.8221\n","Time step 9 (predicting 45 minutes ahead) - ARX RMSE: 48.2418\n","Linear Regression Coefficients (ARX Model):\n","lag_1: 2.2189\n","lag_2: -1.0377\n","lag_3: -0.3853\n","lag_4: -0.0986\n","lag_5: -0.0397\n","lag_6: 0.0027\n","lag_7: -0.0151\n","lag_8: -0.0191\n","lag_9: 0.0091\n","lag_10: -0.0056\n","lag_11: -0.0268\n","lag_12: 0.0448\n","normal: 0.0000\n","carbInput: 0.0000\n","insulinCarbRatio: 0.0000\n","bgInput: 0.0000\n","recommended.carb: 0.0000\n","recommended.net: 0.0000\n","recommended.correction: 0.0000\n","insulinSensitivityFactor: 0.0000\n","targetBloodGlucose: 0.0000\n","insulinOnBoard: 0.0000\n","normal_lag_1: 0.0000\n","normal_lag_2: 0.0000\n","normal_lag_3: 0.0000\n","normal_lag_4: 0.0000\n","normal_lag_5: 0.0000\n","normal_lag_6: 0.0000\n","normal_lag_7: 0.0000\n","normal_lag_8: 0.0000\n","normal_lag_9: 0.0000\n","normal_lag_10: 0.0000\n","normal_lag_11: 0.0000\n","normal_lag_12: 0.0000\n","carbInput_lag_1: 0.0000\n","carbInput_lag_2: 0.0000\n","carbInput_lag_3: 0.0000\n","carbInput_lag_4: 0.0000\n","carbInput_lag_5: 0.0000\n","carbInput_lag_6: 0.0000\n","carbInput_lag_7: 0.0000\n","carbInput_lag_8: 0.0000\n","carbInput_lag_9: 0.0000\n","carbInput_lag_10: 0.0000\n","carbInput_lag_11: 0.0000\n","carbInput_lag_12: 0.0000\n","insulinCarbRatio_lag_1: 0.0000\n","insulinCarbRatio_lag_2: 0.0000\n","insulinCarbRatio_lag_3: 0.0000\n","insulinCarbRatio_lag_4: 0.0000\n","insulinCarbRatio_lag_5: 0.0000\n","insulinCarbRatio_lag_6: 0.0000\n","insulinCarbRatio_lag_7: 0.0000\n","insulinCarbRatio_lag_8: 0.0000\n","insulinCarbRatio_lag_9: 0.0000\n","insulinCarbRatio_lag_10: 0.0000\n","insulinCarbRatio_lag_11: 0.0000\n","insulinCarbRatio_lag_12: 0.0000\n","bgInput_lag_1: 0.0000\n","bgInput_lag_2: 0.0000\n","bgInput_lag_3: 0.0000\n","bgInput_lag_4: 0.0000\n","bgInput_lag_5: 0.0000\n","bgInput_lag_6: 0.0000\n","bgInput_lag_7: 0.0000\n","bgInput_lag_8: 0.0000\n","bgInput_lag_9: 0.0000\n","bgInput_lag_10: 0.0000\n","bgInput_lag_11: 0.0000\n","bgInput_lag_12: 0.0000\n","recommended.carb_lag_1: 0.0000\n","recommended.carb_lag_2: 0.0000\n","recommended.carb_lag_3: 0.0000\n","recommended.carb_lag_4: 0.0000\n","recommended.carb_lag_5: 0.0000\n","recommended.carb_lag_6: 0.0000\n","recommended.carb_lag_7: 0.0000\n","recommended.carb_lag_8: 0.0000\n","recommended.carb_lag_9: 0.0000\n","recommended.carb_lag_10: 0.0000\n","recommended.carb_lag_11: 0.0000\n","recommended.carb_lag_12: 0.0000\n","recommended.net_lag_1: 0.0000\n","recommended.net_lag_2: 0.0000\n","recommended.net_lag_3: 0.0000\n","recommended.net_lag_4: 0.0000\n","recommended.net_lag_5: 0.0000\n","recommended.net_lag_6: 0.0000\n","recommended.net_lag_7: 0.0000\n","recommended.net_lag_8: 0.0000\n","recommended.net_lag_9: 0.0000\n","recommended.net_lag_10: 0.0000\n","recommended.net_lag_11: 0.0000\n","recommended.net_lag_12: 0.0000\n","recommended.correction_lag_1: 0.0000\n","recommended.correction_lag_2: 0.0000\n","recommended.correction_lag_3: 0.0000\n","recommended.correction_lag_4: 0.0000\n","recommended.correction_lag_5: 0.0000\n","recommended.correction_lag_6: 0.0000\n","recommended.correction_lag_7: 0.0000\n","recommended.correction_lag_8: 0.0000\n","recommended.correction_lag_9: 0.0000\n","recommended.correction_lag_10: 0.0000\n","recommended.correction_lag_11: 0.0000\n","recommended.correction_lag_12: 0.0000\n","insulinSensitivityFactor_lag_1: 0.0000\n","insulinSensitivityFactor_lag_2: 0.0000\n","insulinSensitivityFactor_lag_3: 0.0000\n","insulinSensitivityFactor_lag_4: 0.0000\n","insulinSensitivityFactor_lag_5: 0.0000\n","insulinSensitivityFactor_lag_6: 0.0000\n","insulinSensitivityFactor_lag_7: 0.0000\n","insulinSensitivityFactor_lag_8: 0.0000\n","insulinSensitivityFactor_lag_9: 0.0000\n","insulinSensitivityFactor_lag_10: 0.0000\n","insulinSensitivityFactor_lag_11: 0.0000\n","insulinSensitivityFactor_lag_12: 0.0000\n","targetBloodGlucose_lag_1: 0.0000\n","targetBloodGlucose_lag_2: 0.0000\n","targetBloodGlucose_lag_3: 0.0000\n","targetBloodGlucose_lag_4: 0.0000\n","targetBloodGlucose_lag_5: 0.0000\n","targetBloodGlucose_lag_6: 0.0000\n","targetBloodGlucose_lag_7: 0.0000\n","targetBloodGlucose_lag_8: 0.0000\n","targetBloodGlucose_lag_9: 0.0000\n","targetBloodGlucose_lag_10: 0.0000\n","targetBloodGlucose_lag_11: 0.0000\n","targetBloodGlucose_lag_12: 0.0000\n","insulinOnBoard_lag_1: 0.0000\n","insulinOnBoard_lag_2: 0.0000\n","Intercept: 62.8145\n","Time step 12 (predicting 60 minutes ahead) - ARX RMSE: 56.0328\n"]}]},{"cell_type":"markdown","source":["Recursive AR Model"],"metadata":{"id":"il6JtroVCShw"}},{"cell_type":"code","source":["# Recursive forecasting function for the AR model\n","def recursive_forecast_ar_model(data, model, num_steps):\n","    # Initialize a list to store predictions\n","    predictions = []\n","\n","    # Get the last 'num_lags' lag values from the data for initial input\n","    last_known_data = data[[f'lag_{i}' for i in range(1, num_lags + 1)]].iloc[-1].values\n","\n","    # Generate recursive predictions\n","    for _ in range(num_steps):\n","        # Reshape last known data to fit model input format\n","        next_input = last_known_data.reshape(1, -1)\n","\n","        # Predict the next step\n","        next_pred = model.predict(next_input)[0]\n","        predictions.append(next_pred)\n","\n","        # Update the input data by adding the new prediction and dropping the oldest value\n","        last_known_data = np.roll(last_known_data, -1)  # Shift values left\n","        last_known_data[-1] = next_pred  # Add new prediction as the latest lag\n","\n","    return predictions"],"metadata":{"id":"HkIlwTAcIGPg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to train the AR model on 1-step-ahead predictions\n","def train_single_step_ar_model(data):\n","    # Prepare inputs (X) and target (y) for single step\n","    X = data[[f'lag_{i}' for i in range(1, num_lags + 1)]].values\n","    y = data['mg/dl'].shift(-1).dropna().values\n","    X = X[:len(y)]  # Align lengths\n","\n","    # Split into train/test\n","    X_train, X_test = X[:train_size], X[train_size:]\n","    y_train, y_test = y[:train_size], y[train_size:]\n","\n","    # Train the model\n","    model = LinearRegression()\n","    model.fit(X_train, y_train)\n","\n","    # Make predictions on the test set (1-step-ahead for evaluation)\n","    y_pred = model.predict(X_test)\n","\n","    # Calculate performance metric (RMSE)\n","    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","\n","    return model, rmse"],"metadata":{"id":"sHM5bCFsIHft"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train the single-step AR model and evaluate\n","single_step_model, single_step_rmse = train_single_step_ar_model(cgm_data)\n","print(f\"Single-step prediction model - RMSE: {single_step_rmse:.4f}\")\n","\n","# Perform recursive forecasting for different time steps\n","future_steps = [3, 6, 9, 12]  # 15, 30, 45, 60 minutes ahead\n","recursive_results = {}\n","\n","for step in future_steps:\n","    # Recursive prediction\n","    predictions = recursive_forecast_ar_model(cgm_data, single_step_model, step)\n","    recursive_results[f'{step*5} min ahead'] = predictions\n","    print(f\"Recursive prediction for {step*5} minutes ahead: {predictions}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ji0Xv3QuIPyE","executionInfo":{"status":"ok","timestamp":1734030624421,"user_tz":300,"elapsed":441,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}},"outputId":"7dc02338-7f6d-436c-f297-a1b2adc59155"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Single-step prediction model - RMSE: 12.7599\n","Recursive prediction for 15 minutes ahead: [357.7931891426343, 351.55530268934206, 314.09382416826156]\n","Recursive prediction for 30 minutes ahead: [357.7931891426343, 351.55530268934206, 314.09382416826156, 326.6820408463247, 324.0652997421917, 323.17809971553334]\n","Recursive prediction for 45 minutes ahead: [357.7931891426343, 351.55530268934206, 314.09382416826156, 326.6820408463247, 324.0652997421917, 323.17809971553334, 321.87477865026545, 323.6043810269772, 320.62889351165376]\n","Recursive prediction for 60 minutes ahead: [357.7931891426343, 351.55530268934206, 314.09382416826156, 326.6820408463247, 324.0652997421917, 323.17809971553334, 321.87477865026545, 323.6043810269772, 320.62889351165376, 301.00694781772216, 286.82973009934926, 234.0569276848533]\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import mean_squared_error\n","\n","# Function to calculate RMSE for each recursive forecast\n","def calculate_recursive_rmse(data, model, num_steps):\n","    # Initialize list to store RMSE values\n","    rmse_values = {}\n","\n","    # Iterate through each time step to calculate RMSE\n","    for step in num_steps:\n","        # Get the recursive predictions for the current step\n","        predictions = recursive_forecast_ar_model(data, model, step)\n","\n","        # Get the actual values corresponding to this step\n","        actual_values = data['mg/dl'].shift(-step).dropna().values[:len(predictions)]\n","\n","        # Calculate RMSE for this time step\n","        rmse = np.sqrt(mean_squared_error(actual_values, predictions))\n","        rmse_values[f'{step*5} min ahead'] = rmse\n","        print(f\"RMSE for recursive forecast {step*5} minutes ahead: {rmse:.4f}\")\n","\n","    return rmse_values\n","\n","# Calculate RMSE for recursive forecasts on the test set\n","recursive_rmse = calculate_recursive_rmse(cgm_data[train_size:], single_step_model, future_steps)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LlBYNsjVInan","executionInfo":{"status":"ok","timestamp":1734030627125,"user_tz":300,"elapsed":277,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}},"outputId":"99c09b39-4f65-45ba-90e1-94b442fa258f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["RMSE for recursive forecast 15 minutes ahead: 121.9514\n","RMSE for recursive forecast 30 minutes ahead: 86.4772\n","RMSE for recursive forecast 45 minutes ahead: 68.8624\n","RMSE for recursive forecast 60 minutes ahead: 57.5662\n"]}]},{"cell_type":"markdown","source":["LASSO Regression"],"metadata":{"id":"NkjsoBRYIvw9"}},{"cell_type":"code","source":["from sklearn.linear_model import Lasso\n","\n","# Function to train and evaluate a Lasso regression model for a specified prediction step\n","def train_lasso_model(data, target_step, alpha=0.1, max_iter=5000):\n","    # Prepare inputs (X) and target (y)\n","    X = data[[f'lag_{i}' for i in range(1, num_lags + 1)]].values\n","    y = data['mg/dl'].shift(-target_step).dropna().values\n","    X = X[:len(y)]  # Align lengths\n","\n","    # Split into train/test\n","    X_train, X_test = X[:train_size], X[train_size:]\n","    y_train, y_test = y[:train_size], y[train_size:]\n","\n","    # Train the Lasso model with specified alpha (regularization strength)\n","    lasso_model = Lasso(alpha=alpha, max_iter=max_iter)\n","    lasso_model.fit(X_train, y_train)\n","\n","    # Make predictions\n","    y_pred = lasso_model.predict(X_test)\n","\n","    # Calculate performance metric (RMSE)\n","    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","\n","    return lasso_model, rmse"],"metadata":{"id":"W0vXtL8pM4Op"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train and evaluate Lasso models for different time steps\n","lasso_results = {}\n","for step in time_steps:\n","    model, rmse = train_lasso_model(cgm_data, step, alpha=0.1, max_iter=5000)\n","    lasso_results[f'{step*5} min ahead'] = {'Model': model, 'RMSE': rmse}\n","    print(f\"Lasso regression for {step*5} minutes ahead - RMSE: {rmse:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"btYD6roIM5XK","executionInfo":{"status":"ok","timestamp":1734030761579,"user_tz":300,"elapsed":128523,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}},"outputId":"f6bc08c2-197d-44d4-f7b2-3fe7512bebd2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Lasso regression for 15 minutes ahead - RMSE: 23.9630\n","Lasso regression for 30 minutes ahead - RMSE: 37.6564\n","Lasso regression for 45 minutes ahead - RMSE: 48.2408\n","Lasso regression for 60 minutes ahead - RMSE: 56.0311\n"]}]},{"cell_type":"markdown","source":["Ridge Regression"],"metadata":{"id":"3jrB_xynPg3_"}},{"cell_type":"code","source":["from sklearn.linear_model import Ridge\n","\n","# Function to train and evaluate a Ridge regression model for a specified prediction step\n","def train_ridge_model(data, target_step, alpha=1.0):\n","    # Prepare inputs (X) and target (y)\n","    X = data[[f'lag_{i}' for i in range(1, num_lags + 1)]].values\n","    y = data['mg/dl'].shift(-target_step).dropna().values\n","    X = X[:len(y)]  # Align lengths\n","\n","    # Split into train/test\n","    X_train, X_test = X[:train_size], X[train_size:]\n","    y_train, y_test = y[:train_size], y[train_size:]\n","\n","    # Train the Ridge model with specified alpha (regularization strength)\n","    ridge_model = Ridge(alpha=alpha)\n","    ridge_model.fit(X_train, y_train)\n","\n","    # Make predictions\n","    y_pred = ridge_model.predict(X_test)\n","\n","    # Calculate performance metric (RMSE)\n","    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","\n","    return ridge_model, rmse\n","\n","# Train and evaluate Ridge models for different time steps\n","ridge_results = {}\n","alpha_value = 1.0  # Adjust alpha as needed for regularization strength\n","for step in time_steps:\n","    model, rmse = train_ridge_model(cgm_data, step, alpha=alpha_value)\n","    ridge_results[f'{step*5} min ahead'] = {'Model': model, 'RMSE': rmse}\n","    print(f\"Ridge regression for {step*5} minutes ahead - RMSE: {rmse:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GyVdNSkKSL5j","executionInfo":{"status":"ok","timestamp":1734030767833,"user_tz":300,"elapsed":320,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}},"outputId":"5ab440ed-9a0a-4199-d42f-32fccbbe9aec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ridge regression for 15 minutes ahead - RMSE: 23.9630\n","Ridge regression for 30 minutes ahead - RMSE: 37.6561\n","Ridge regression for 45 minutes ahead - RMSE: 48.2410\n","Ridge regression for 60 minutes ahead - RMSE: 56.0313\n"]}]},{"cell_type":"markdown","source":["Elastic Net Regression"],"metadata":{"id":"l7xmEKZHYzVa"}},{"cell_type":"code","source":["from sklearn.linear_model import ElasticNet\n","\n","# Function to train and evaluate ElasticNet model\n","def train_elastic_net_model(data, target_step, alpha=1.0, l1_ratio=0.5):\n","    # Prepare inputs (X) and target (y)\n","    X = data[[f'lag_{i}' for i in range(1, num_lags + 1)]].values\n","    y = data['mg/dl'].shift(-target_step).dropna().values\n","    X = X[:len(y)]  # Align lengths\n","\n","    # Split into train/test\n","    X_train, X_test = X[:train_size], X[train_size:]\n","    y_train, y_test = y[:train_size], y[train_size:]\n","\n","    # Train the ElasticNet model\n","    elastic_net_model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n","    elastic_net_model.fit(X_train, y_train)\n","\n","    # Make predictions\n","    y_pred = elastic_net_model.predict(X_test)\n","\n","    # Calculate performance metric (RMSE)\n","    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","\n","    return elastic_net_model, rmse\n","\n","# Train and evaluate ElasticNet models for different time steps\n","elastic_net_results = {}\n","alpha_value = 1.0  # Regularization strength (larger values => more regularization)\n","l1_ratio_value = 0.5  # Mix ratio between Lasso (L1) and Ridge (L2) regularization\n","for step in time_steps:\n","    model, rmse = train_elastic_net_model(cgm_data, step, alpha=alpha_value, l1_ratio=l1_ratio_value)\n","    elastic_net_results[f'{step*5} min ahead'] = {'Model': model, 'RMSE': rmse}\n","    print(f\"ElasticNet for {step*5} minutes ahead - RMSE: {rmse:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xelNG6-fY-hH","executionInfo":{"status":"ok","timestamp":1734030833592,"user_tz":300,"elapsed":65308,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}},"outputId":"01b674dd-2ec6-4f78-87c1-34be973bcbed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ElasticNet for 15 minutes ahead - RMSE: 23.9780\n","ElasticNet for 30 minutes ahead - RMSE: 37.6660\n","ElasticNet for 45 minutes ahead - RMSE: 48.2455\n","ElasticNet for 60 minutes ahead - RMSE: 56.0317\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.740e+05, tolerance: 1.502e+05\n","  model = cd_fast.enet_coordinate_descent(\n"]}]},{"cell_type":"markdown","source":["Huber"],"metadata":{"id":"dElBbo6IZGGM"}},{"cell_type":"code","source":["from sklearn.linear_model import HuberRegressor\n","\n","# Function to train and evaluate Huber regression model\n","def train_huber_model(data, target_step, epsilon=1.35):\n","    # Prepare inputs (X) and target (y)\n","    X = data[[f'lag_{i}' for i in range(1, num_lags + 1)]].values\n","    y = data['mg/dl'].shift(-target_step).dropna().values\n","    X = X[:len(y)]  # Align lengths\n","\n","    # Split into train/test\n","    X_train, X_test = X[:train_size], X[train_size:]\n","    y_train, y_test = y[:train_size], y[train_size:]\n","\n","    # Train the Huber regression model\n","    huber_model = HuberRegressor(epsilon=epsilon, max_iter=1000)\n","    huber_model.fit(X_train, y_train)\n","\n","    # Make predictions\n","    y_pred = huber_model.predict(X_test)\n","\n","    # Calculate performance metric (RMSE)\n","    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","\n","    return huber_model, rmse\n","\n","# Train and evaluate Huber models for different time steps\n","huber_results = {}\n","epsilon_value = 1.35  # Huber loss function parameter (controls the threshold between quadratic and linear loss)\n","for step in time_steps:\n","    model, rmse = train_huber_model(cgm_data, step, epsilon=epsilon_value)\n","    huber_results[f'{step*5} min ahead'] = {'Model': model, 'RMSE': rmse}\n","    print(f\"Huber for {step*5} minutes ahead - RMSE: {rmse:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JaMt0glzZLSK","executionInfo":{"status":"ok","timestamp":1734031018307,"user_tz":300,"elapsed":184747,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}},"outputId":"c8fe0ad9-d964-4326-a1a4-9bee1b770a09"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Huber for 15 minutes ahead - RMSE: 24.8391\n","Huber for 30 minutes ahead - RMSE: 38.7629\n","Huber for 45 minutes ahead - RMSE: 49.4807\n","Huber for 60 minutes ahead - RMSE: 57.2745\n"]}]},{"cell_type":"markdown","source":["Random Forest"],"metadata":{"id":"_GyZIr2Ca_Mo"}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_squared_error\n","\n","# Function to train and evaluate Random Forest model\n","def train_rf_model(data, target_step, n_estimators=100, max_depth=None, random_state=42):\n","    # Prepare inputs (X) and target (y)\n","    X = data[[f'lag_{i}' for i in range(1, num_lags + 1)]].values\n","    y = data['mg/dl'].shift(-target_step).dropna().values\n","    X = X[:len(y)]  # Align lengths\n","\n","    # Split into train/test\n","    X_train, X_test = X[:train_size], X[train_size:]\n","    y_train, y_test = y[:train_size], y[train_size:]\n","\n","    # Train the Random Forest model\n","    rf_model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=random_state)\n","    rf_model.fit(X_train, y_train)\n","\n","    # Make predictions\n","    y_pred = rf_model.predict(X_test)\n","\n","    # Calculate performance metric (RMSE)\n","    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","\n","    return rf_model, rmse\n","\n","# Train and evaluate Random Forest models for different time steps\n","rf_results = {}\n","for step in time_steps:\n","    model, rmse = train_rf_model(cgm_data, step, n_estimators=100, max_depth=10)\n","    rf_results[f'{step*5} min ahead'] = {'Model': model, 'RMSE': rmse}\n","    print(f\"Random Forest for {step*5} minutes ahead - RMSE: {rmse:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ccFkUnHchZzE","executionInfo":{"status":"ok","timestamp":1734031676877,"user_tz":300,"elapsed":658577,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}},"outputId":"018a73b8-3e95-4c7b-8621-2a2094aa4892"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Random Forest for 15 minutes ahead - RMSE: 22.6772\n","Random Forest for 30 minutes ahead - RMSE: 36.1088\n","Random Forest for 45 minutes ahead - RMSE: 46.7690\n","Random Forest for 60 minutes ahead - RMSE: 54.7801\n"]}]},{"cell_type":"markdown","source":["XGBoost"],"metadata":{"id":"opeXoGyzbAGT"}},{"cell_type":"code","source":["import xgboost as xgb\n","from sklearn.metrics import mean_squared_error\n","\n","# Function to train and evaluate XGBoost model\n","def train_xgb_model(data, target_step, num_boost_round=100, learning_rate=0.1, max_depth=30, random_state=42):\n","    # Prepare inputs (X) and target (y)\n","    X = data[[f'lag_{i}' for i in range(1, num_lags + 1)]].values\n","    y = data['mg/dl'].shift(-target_step).dropna().values\n","    X = X[:len(y)]  # Align lengths\n","\n","    # Split into train/test\n","    X_train, X_test = X[:train_size], X[train_size:]\n","    y_train, y_test = y[:train_size], y[train_size:]\n","\n","    # Create DMatrix for XGBoost\n","    dtrain = xgb.DMatrix(X_train, label=y_train)\n","    dtest = xgb.DMatrix(X_test, label=y_test)\n","\n","    # Set parameters for XGBoost\n","    params = {\n","        'objective': 'reg:squarederror',  # Regression task (squared error loss)\n","        'eval_metric': 'rmse',            # Metric to evaluate model\n","        'max_depth': max_depth,           # Depth of the trees\n","        'learning_rate': learning_rate,  # Step size shrinkage\n","        'random_state': random_state,    # For reproducibility\n","    }\n","\n","    # Train the XGBoost model\n","    model = xgb.train(params, dtrain, num_boost_round=num_boost_round)\n","\n","    # Make predictions\n","    y_pred = model.predict(dtest)\n","\n","    # Calculate performance metric (RMSE)\n","    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","\n","    return model, rmse\n","\n","# Train and evaluate XGBoost models for different time steps\n","xgb_results = {}\n","for step in time_steps:\n","    model, rmse = train_xgb_model(cgm_data, step, num_boost_round=100, learning_rate=0.1, max_depth=10)\n","    xgb_results[f'{step*5} min ahead'] = {'Model': model, 'RMSE': rmse}\n","    print(f\"XGBoost for {step*5} minutes ahead - RMSE: {rmse:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qFksTsoXoejo","executionInfo":{"status":"ok","timestamp":1734031710152,"user_tz":300,"elapsed":33317,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}},"outputId":"ed05623d-f68d-413f-a2d7-b27abd883612"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["XGBoost for 15 minutes ahead - RMSE: 22.5142\n","XGBoost for 30 minutes ahead - RMSE: 35.9690\n","XGBoost for 45 minutes ahead - RMSE: 46.7181\n","XGBoost for 60 minutes ahead - RMSE: 54.8589\n"]}]},{"cell_type":"code","source":["import xgboost as xgb\n","from sklearn.metrics import mean_squared_error\n","import numpy as np\n","\n","# Function to train and evaluate XGBoost model with ARX features\n","def train_xgb_arx_model(data, target_step, num_boost_round=100, learning_rate=0.1, max_depth=10, random_state=42):\n","    # Prepare inputs (X) and target (y)\n","    # Use all lagged features (CGM + Bolus variables)\n","    feature_columns = [col for col in data.columns if col.startswith('lag_') or '_lag_' in col]\n","    X = data[feature_columns].values\n","    y = data['mg/dl'].shift(-target_step).dropna().values\n","    X = X[:len(y)]  # Align lengths\n","\n","    # Split into train/test\n","    X_train, X_test = X[:train_size], X[train_size:]\n","    y_train, y_test = y[:train_size], y[train_size:]\n","\n","    # Create DMatrix for XGBoost\n","    dtrain = xgb.DMatrix(X_train, label=y_train)\n","    dtest = xgb.DMatrix(X_test, label=y_test)\n","\n","    # Set parameters for XGBoost\n","    params = {\n","        'objective': 'reg:squarederror',  # Regression task (squared error loss)\n","        'eval_metric': 'rmse',            # Metric to evaluate model\n","        'max_depth': max_depth,           # Depth of the trees\n","        'learning_rate': learning_rate,   # Step size shrinkage\n","        'random_state': random_state,     # For reproducibility\n","    }\n","\n","    # Train the XGBoost model\n","    model = xgb.train(params, dtrain, num_boost_round=num_boost_round)\n","\n","    # Make predictions\n","    y_pred = model.predict(dtest)\n","\n","    # Calculate performance metric (RMSE)\n","    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","\n","    return model, rmse\n","\n","# Train and evaluate XGBoost models for different time steps\n","xgb_arx_results = {}\n","for step in time_steps:\n","    model, rmse = train_xgb_arx_model(merged_data, step, num_boost_round=100, learning_rate=0.1, max_depth=10)\n","    xgb_arx_results[f'{step*5} min ahead'] = {'Model': model, 'RMSE': rmse}\n","    print(f\"XGBoost (ARX) for {step*5} minutes ahead - RMSE: {rmse:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4rX7CK7TBFPM","executionInfo":{"status":"ok","timestamp":1734031797817,"user_tz":300,"elapsed":87704,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}},"outputId":"4581cdbe-75f0-4bfd-ab1b-89374a332a75"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["XGBoost (ARX) for 15 minutes ahead - RMSE: 22.5218\n","XGBoost (ARX) for 30 minutes ahead - RMSE: 35.9537\n","XGBoost (ARX) for 45 minutes ahead - RMSE: 46.7137\n","XGBoost (ARX) for 60 minutes ahead - RMSE: 54.8769\n"]}]}]}