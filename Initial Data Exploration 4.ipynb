{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO3R3qXs2IXiwSXzV49WiRy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OQlCqHTP9N4F","executionInfo":{"status":"ok","timestamp":1734032689312,"user_tz":300,"elapsed":25450,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}},"outputId":"7cb03a24-ef5d-45a8-e473-5913c0e3b8b5"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["Autoregressive Linear Regression on just Blood Glucose"],"metadata":{"id":"tqnTDSRvEHjU"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import train_test_split\n","\n","# Load the data\n","file_path = '/content/drive/My Drive/Thesis/Subject4.xlsx'\n","cgm_data = pd.read_excel(file_path, sheet_name='CGM')"],"metadata":{"id":"ud1OmyUu2v7P","executionInfo":{"status":"ok","timestamp":1734032719203,"user_tz":300,"elapsed":29901,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Preprocess - Round to nearest 5 minutes\n","cgm_data['date'] = pd.to_datetime(cgm_data['date']).dt.round('5min')\n","\n","# Filter out rows where mg/dl is > 400 or missing values\n","cgm_data = cgm_data[cgm_data['mg/dl'] <= 400].dropna(subset=['mg/dl'])\n","\n","# Drop duplicates and sort\n","cgm_data = cgm_data.drop_duplicates(subset='date').reset_index(drop=True)\n","cgm_data = cgm_data.sort_values(by='date').reset_index(drop=True)"],"metadata":{"id":"douYzyaW2xjy","executionInfo":{"status":"ok","timestamp":1734032719208,"user_tz":300,"elapsed":27,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Generate AR Features (using past 12 readings as input)\n","num_lags = 12 # Using the past 12 values\n","for lag in range(1, num_lags + 1):\n","    cgm_data[f'lag_{lag}'] = cgm_data['mg/dl'].shift(lag)\n","\n","cgm_data = cgm_data.dropna().reset_index(drop=True)"],"metadata":{"id":"CRxaWkzv2x6u","executionInfo":{"status":"ok","timestamp":1734032719516,"user_tz":300,"elapsed":329,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Split into train/test (80% train, 20% test by time order)\n","train_size = int(len(cgm_data) * 0.8)\n","train_data = cgm_data[:train_size]\n","test_data = cgm_data[train_size:]"],"metadata":{"id":"OkoX5i1J2002","executionInfo":{"status":"ok","timestamp":1734032719517,"user_tz":300,"elapsed":15,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Define function to train and evaluate for different time steps\n","def train_ar_model(data, target_step):\n","    # Prepare inputs (X) and target (y)\n","    X = data[[f'lag_{i}' for i in range(1, num_lags + 1)]].values\n","    y = data['mg/dl'].shift(-target_step).dropna().values\n","    X = X[:len(y)]  # Align lengths\n","\n","    # Split into train/test\n","    X_train, X_test = X[:train_size], X[train_size:]\n","    y_train, y_test = y[:train_size], y[train_size:]\n","\n","    # Train the model\n","    model = LinearRegression()\n","    model.fit(X_train, y_train)\n","\n","    # Make predictions\n","    y_pred = model.predict(X_test)\n","\n","    # Calculate performance metric (RMSE)\n","    rmse = np.sqrt(mean_squared_error(y_test, y_pred))  # Use np.sqrt on MSE\n","\n","    # Display the coefficients\n","    coefficients = model.coef_\n","    intercept = model.intercept_\n","\n","    print(\"Linear Regression Coefficients (lags):\")\n","    for i, coef in enumerate(coefficients, start=1):\n","      print(f\"Lag {i}: {coef:.4f}\")\n","    print(f\"Intercept: {intercept:.4f}\")\n","\n","    return model, rmse"],"metadata":{"id":"x97E22Mm22Zs","executionInfo":{"status":"ok","timestamp":1734032719517,"user_tz":300,"elapsed":11,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Train models for different time step targets and evaluate\n","time_steps = [3, 6, 9, 12]  # Corresponding to 15, 30, 45, 60 minutes\n","results = {}\n","\n","for step in time_steps:\n","    model, rmse = train_ar_model(cgm_data, step)\n","    results[f'{step*5} min ahead'] = {'Model': model, 'RMSE': rmse}\n","    print(f\"Time step {step} (predicting {step*5} minutes ahead) - RMSE: {rmse:.4f}\")\n","\n","# Results dictionary now contains trained models and RMSE for each time target"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0wp2DlsI24Qc","executionInfo":{"status":"ok","timestamp":1734032720515,"user_tz":300,"elapsed":1007,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}},"outputId":"038428ce-864c-4cf3-e180-20d99d07cecf"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Linear Regression Coefficients (lags):\n","Lag 1: 2.2540\n","Lag 2: -0.9181\n","Lag 3: -0.4313\n","Lag 4: 0.0462\n","Lag 5: 0.0655\n","Lag 6: -0.0389\n","Lag 7: -0.0229\n","Lag 8: -0.0055\n","Lag 9: -0.0286\n","Lag 10: -0.0134\n","Lag 11: 0.0185\n","Lag 12: -0.0071\n","Intercept: 11.5268\n","Time step 3 (predicting 15 minutes ahead) - RMSE: 18.3526\n","Linear Regression Coefficients (lags):\n","Lag 1: 2.4552\n","Lag 2: -1.0887\n","Lag 3: -0.4957\n","Lag 4: 0.0383\n","Lag 5: 0.0460\n","Lag 6: -0.0446\n","Lag 7: -0.0370\n","Lag 8: -0.0084\n","Lag 9: -0.0382\n","Lag 10: -0.0131\n","Lag 11: 0.0287\n","Lag 12: -0.0132\n","Intercept: 24.1659\n","Time step 6 (predicting 30 minutes ahead) - RMSE: 27.9059\n","Linear Regression Coefficients (lags):\n","Lag 1: 2.4599\n","Lag 2: -1.1517\n","Lag 3: -0.5072\n","Lag 4: 0.0263\n","Lag 5: 0.0425\n","Lag 6: -0.0529\n","Lag 7: -0.0382\n","Lag 8: -0.0003\n","Lag 9: -0.0497\n","Lag 10: -0.0133\n","Lag 11: 0.0398\n","Lag 12: -0.0201\n","Intercept: 37.4993\n","Time step 9 (predicting 45 minutes ahead) - RMSE: 35.2443\n","Linear Regression Coefficients (lags):\n","Lag 1: 2.3242\n","Lag 2: -1.1189\n","Lag 3: -0.4938\n","Lag 4: 0.0229\n","Lag 5: 0.0472\n","Lag 6: -0.0620\n","Lag 7: -0.0382\n","Lag 8: 0.0069\n","Lag 9: -0.0628\n","Lag 10: 0.0161\n","Lag 11: 0.0220\n","Lag 12: -0.0211\n","Intercept: 50.6032\n","Time step 12 (predicting 60 minutes ahead) - RMSE: 40.6424\n"]}]},{"cell_type":"markdown","source":["ARX Model with Blood Glucose and Bolus Data"],"metadata":{"id":"g3a743rVoLM7"}},{"cell_type":"code","source":["# Load Bolus data\n","bolus_data = pd.read_excel(file_path, sheet_name='Bolus')\n","\n","# Preprocess Bolus data - Round to nearest 5 minutes and fill missing values with 0\n","bolus_data['date'] = pd.to_datetime(bolus_data['date']).dt.round('5min')\n","bolus_data = bolus_data.fillna(0)  # Set missing values to 0\n","\n","# Merge Bolus data with CGM data on date\n","merged_data = pd.merge(cgm_data, bolus_data, on='date', how='left').fillna(0)  # Fill missing values after merge\n","\n","# Generate lag features for Bolus variables\n","bolus_vars = ['normal', 'carbInput', 'insulinCarbRatio', 'bgInput', 'recommended.carb', 'recommended.net',\n","              'recommended.correction', 'insulinSensitivityFactor', 'targetBloodGlucose', 'insulinOnBoard']\n","\n","for var in bolus_vars:\n","    for lag in range(1, num_lags + 1):\n","        merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","\n","# Drop rows with NaNs introduced by shifting\n","merged_data = merged_data.dropna().reset_index(drop=True)\n","\n","# Update train/test split based on merged data\n","train_data = merged_data[:train_size]\n","test_data = merged_data[train_size:]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Jt4GA81BcX0","executionInfo":{"status":"ok","timestamp":1734032723382,"user_tz":300,"elapsed":2874,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}},"outputId":"9153132d-4e35-4c5a-f693-53e488d0c0b6"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n"]}]},{"cell_type":"code","source":["# Modify train_ar_model function to include all lagged features\n","def train_arx_model(data, target_step):\n","    # Prepare inputs (X) - using lag features from both mg/dl and Bolus data\n","    lag_columns = [f'lag_{i}' for i in range(1, num_lags + 1)] + \\\n","                  [f'{var}_lag_{i}' for var in bolus_vars for i in range(1, num_lags + 1)]\n","    X = data[lag_columns].values\n","    y = data['mg/dl'].shift(-target_step).dropna().values\n","    X = X[:len(y)]  # Align lengths\n","\n","    # Split into train/test\n","    X_train, X_test = X[:train_size], X[train_size:]\n","    y_train, y_test = y[:train_size], y[train_size:]\n","\n","    # Train the model\n","    model = LinearRegression()\n","    model.fit(X_train, y_train)\n","\n","    # Make predictions\n","    y_pred = model.predict(X_test)\n","\n","    # Calculate performance metric (RMSE)\n","    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","\n","    # Extract coefficients and intercept\n","    coefficients = model.coef_\n","    intercept = model.intercept_\n","\n","    # Display the coefficients\n","    print(\"Linear Regression Coefficients (ARX Model):\")\n","    feature_names = merged_data.drop(columns=['date', 'mg/dl']).columns\n","    for feature, coef in zip(feature_names, coefficients):\n","      print(f\"{feature}: {coef:.4f}\")\n","    print(f\"Intercept: {intercept:.4f}\")\n","\n","    return model, rmse"],"metadata":{"id":"ZAZtpnsdBmZ_","executionInfo":{"status":"ok","timestamp":1734032723388,"user_tz":300,"elapsed":15,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Train ARX models for different time steps and evaluate\n","results_arx = {}\n","for step in time_steps:\n","    model, rmse = train_arx_model(merged_data, step)\n","    results_arx[f'{step*5} min ahead'] = {'Model': model, 'RMSE': rmse}\n","    print(f\"Time step {step} (predicting {step*5} minutes ahead) - ARX RMSE: {rmse:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5LG4pUQsB1R-","executionInfo":{"status":"ok","timestamp":1734032749391,"user_tz":300,"elapsed":26016,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}},"outputId":"fa08ad43-ca3b-45c5-b836-7ad5e3628741"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Linear Regression Coefficients (ARX Model):\n","lag_1: 2.2491\n","lag_2: -0.9148\n","lag_3: -0.4294\n","lag_4: 0.0465\n","lag_5: 0.0662\n","lag_6: -0.0387\n","lag_7: -0.0232\n","lag_8: -0.0059\n","lag_9: -0.0288\n","lag_10: -0.0138\n","lag_11: 0.0178\n","lag_12: -0.0058\n","normal: -0.6463\n","carbInput: -0.5890\n","insulinCarbRatio: -0.9634\n","bgInput: -1.0406\n","recommended.carb: -1.2460\n","recommended.net: -1.4947\n","recommended.correction: -1.6209\n","insulinSensitivityFactor: -1.2336\n","targetBloodGlucose: -1.2383\n","insulinOnBoard: -1.2054\n","normal_lag_1: -0.7325\n","normal_lag_2: -0.0633\n","normal_lag_3: -0.2132\n","normal_lag_4: -0.1816\n","normal_lag_5: -0.0353\n","normal_lag_6: 0.0775\n","normal_lag_7: 0.3058\n","normal_lag_8: 0.4261\n","normal_lag_9: 0.3634\n","normal_lag_10: 0.4835\n","normal_lag_11: 0.5262\n","normal_lag_12: 0.5176\n","carbInput_lag_1: 0.6122\n","carbInput_lag_2: 0.4762\n","carbInput_lag_3: 0.1167\n","carbInput_lag_4: 0.1069\n","carbInput_lag_5: -0.0666\n","carbInput_lag_6: 0.2182\n","carbInput_lag_7: 0.2330\n","carbInput_lag_8: 0.2398\n","carbInput_lag_9: 0.1883\n","carbInput_lag_10: -0.1260\n","carbInput_lag_11: -0.3265\n","carbInput_lag_12: -0.2622\n","insulinCarbRatio_lag_1: -0.3121\n","insulinCarbRatio_lag_2: -0.2483\n","insulinCarbRatio_lag_3: -0.0277\n","insulinCarbRatio_lag_4: -0.0298\n","insulinCarbRatio_lag_5: -0.0193\n","insulinCarbRatio_lag_6: 0.0385\n","insulinCarbRatio_lag_7: 0.0232\n","insulinCarbRatio_lag_8: -0.0275\n","insulinCarbRatio_lag_9: -0.0261\n","insulinCarbRatio_lag_10: -0.0333\n","insulinCarbRatio_lag_11: -0.0292\n","insulinCarbRatio_lag_12: 0.0050\n","bgInput_lag_1: -0.0074\n","bgInput_lag_2: -0.0079\n","bgInput_lag_3: 7.7553\n","bgInput_lag_4: 6.4221\n","bgInput_lag_5: 3.4717\n","bgInput_lag_6: 1.6963\n","bgInput_lag_7: -0.9779\n","bgInput_lag_8: -1.9007\n","bgInput_lag_9: -1.4380\n","bgInput_lag_10: -2.6974\n","bgInput_lag_11: -3.1817\n","bgInput_lag_12: -4.2608\n","recommended.carb_lag_1: -6.1973\n","recommended.carb_lag_2: -4.7750\n","recommended.carb_lag_3: -4.1247\n","recommended.carb_lag_4: -2.9054\n","recommended.carb_lag_5: -0.8365\n","recommended.carb_lag_6: -1.3884\n","recommended.carb_lag_7: -1.4101\n","recommended.carb_lag_8: -2.0181\n","recommended.carb_lag_9: -1.9198\n","recommended.carb_lag_10: -2.0810\n","recommended.carb_lag_11: -1.8901\n","recommended.carb_lag_12: -0.8667\n","recommended.net_lag_1: -0.2132\n","recommended.net_lag_2: -0.7411\n","recommended.net_lag_3: 3.0353\n","recommended.net_lag_4: 3.6852\n","recommended.net_lag_5: 1.3551\n","recommended.net_lag_6: 0.3547\n","recommended.net_lag_7: 0.7230\n","recommended.net_lag_8: 3.1919\n","recommended.net_lag_9: 2.7950\n","recommended.net_lag_10: 2.5711\n","recommended.net_lag_11: 2.4196\n","recommended.net_lag_12: 0.4286\n","recommended.correction_lag_1: 0.4801\n","recommended.correction_lag_2: 0.3432\n","recommended.correction_lag_3: -0.2805\n","recommended.correction_lag_4: -0.5251\n","recommended.correction_lag_5: -0.2602\n","recommended.correction_lag_6: -0.3306\n","recommended.correction_lag_7: -0.1362\n","recommended.correction_lag_8: -0.0082\n","recommended.correction_lag_9: 0.1443\n","recommended.correction_lag_10: 0.1196\n","recommended.correction_lag_11: 0.0888\n","recommended.correction_lag_12: 0.0772\n","insulinSensitivityFactor_lag_1: 0.1791\n","insulinSensitivityFactor_lag_2: 0.1417\n","insulinSensitivityFactor_lag_3: 0.2372\n","insulinSensitivityFactor_lag_4: 0.3296\n","insulinSensitivityFactor_lag_5: 0.1814\n","insulinSensitivityFactor_lag_6: 0.1413\n","insulinSensitivityFactor_lag_7: 0.0477\n","insulinSensitivityFactor_lag_8: 0.0316\n","insulinSensitivityFactor_lag_9: -0.0465\n","insulinSensitivityFactor_lag_10: -0.0205\n","insulinSensitivityFactor_lag_11: -0.0083\n","insulinSensitivityFactor_lag_12: -0.0466\n","targetBloodGlucose_lag_1: -0.0923\n","targetBloodGlucose_lag_2: -0.0745\n","targetBloodGlucose_lag_3: -3.2795\n","targetBloodGlucose_lag_4: -2.8560\n","targetBloodGlucose_lag_5: -1.4814\n","targetBloodGlucose_lag_6: -1.9142\n","targetBloodGlucose_lag_7: -1.1494\n","targetBloodGlucose_lag_8: -1.0802\n","targetBloodGlucose_lag_9: -0.9909\n","targetBloodGlucose_lag_10: -0.8890\n","targetBloodGlucose_lag_11: -0.6785\n","targetBloodGlucose_lag_12: 0.0785\n","insulinOnBoard_lag_1: 0.6571\n","insulinOnBoard_lag_2: 0.0555\n","Intercept: 11.4334\n","Time step 3 (predicting 15 minutes ahead) - ARX RMSE: 18.4668\n","Linear Regression Coefficients (ARX Model):\n","lag_1: 2.4482\n","lag_2: -1.0830\n","lag_3: -0.4927\n","lag_4: 0.0389\n","lag_5: 0.0468\n","lag_6: -0.0445\n","lag_7: -0.0376\n","lag_8: -0.0091\n","lag_9: -0.0385\n","lag_10: -0.0131\n","lag_11: 0.0283\n","lag_12: -0.0125\n","normal: -1.7769\n","carbInput: -1.9666\n","insulinCarbRatio: -2.4296\n","bgInput: -2.3549\n","recommended.carb: -2.6864\n","recommended.net: -2.9653\n","recommended.correction: -2.8203\n","insulinSensitivityFactor: -1.8628\n","targetBloodGlucose: -1.5599\n","insulinOnBoard: -1.6564\n","normal_lag_1: -1.4330\n","normal_lag_2: -0.8623\n","normal_lag_3: -0.1262\n","normal_lag_4: 0.0392\n","normal_lag_5: 0.2650\n","normal_lag_6: 0.4413\n","normal_lag_7: 0.7858\n","normal_lag_8: 0.9378\n","normal_lag_9: 0.9692\n","normal_lag_10: 1.0761\n","normal_lag_11: 1.0526\n","normal_lag_12: 0.9692\n","carbInput_lag_1: 1.0727\n","carbInput_lag_2: 0.9001\n","carbInput_lag_3: 0.2728\n","carbInput_lag_4: 0.3739\n","carbInput_lag_5: 0.1619\n","carbInput_lag_6: 0.3305\n","carbInput_lag_7: 0.1224\n","carbInput_lag_8: 0.1122\n","carbInput_lag_9: -0.0383\n","carbInput_lag_10: -0.4137\n","carbInput_lag_11: -0.6784\n","carbInput_lag_12: -0.5813\n","insulinCarbRatio_lag_1: -0.5975\n","insulinCarbRatio_lag_2: -0.4917\n","insulinCarbRatio_lag_3: -0.0184\n","insulinCarbRatio_lag_4: -0.0283\n","insulinCarbRatio_lag_5: -0.0346\n","insulinCarbRatio_lag_6: 0.0168\n","insulinCarbRatio_lag_7: -0.0162\n","insulinCarbRatio_lag_8: -0.0469\n","insulinCarbRatio_lag_9: -0.0343\n","insulinCarbRatio_lag_10: -0.0506\n","insulinCarbRatio_lag_11: -0.0594\n","insulinCarbRatio_lag_12: -0.0075\n","bgInput_lag_1: 0.0072\n","bgInput_lag_2: 0.0200\n","bgInput_lag_3: 10.4820\n","bgInput_lag_4: 7.1817\n","bgInput_lag_5: 3.1092\n","bgInput_lag_6: 0.7349\n","bgInput_lag_7: -3.1652\n","bgInput_lag_8: -5.1659\n","bgInput_lag_9: -6.4065\n","bgInput_lag_10: -7.9647\n","bgInput_lag_11: -7.7384\n","bgInput_lag_12: -8.2705\n","recommended.carb_lag_1: -10.3772\n","recommended.carb_lag_2: -8.6702\n","recommended.carb_lag_3: -6.3149\n","recommended.carb_lag_4: -4.8741\n","recommended.carb_lag_5: -2.8039\n","recommended.carb_lag_6: -3.8297\n","recommended.carb_lag_7: -3.7983\n","recommended.carb_lag_8: -3.7335\n","recommended.carb_lag_9: -3.2152\n","recommended.carb_lag_10: -3.2525\n","recommended.carb_lag_11: -3.2527\n","recommended.carb_lag_12: -1.6945\n","recommended.net_lag_1: -0.7860\n","recommended.net_lag_2: -0.9109\n","recommended.net_lag_3: 4.6908\n","recommended.net_lag_4: 5.7827\n","recommended.net_lag_5: 3.8731\n","recommended.net_lag_6: 3.1361\n","recommended.net_lag_7: 4.1980\n","recommended.net_lag_8: 5.4123\n","recommended.net_lag_9: 3.9279\n","recommended.net_lag_10: 3.8785\n","recommended.net_lag_11: 4.2312\n","recommended.net_lag_12: 1.2659\n","recommended.correction_lag_1: -0.2980\n","recommended.correction_lag_2: -1.3645\n","recommended.correction_lag_3: -0.6107\n","recommended.correction_lag_4: -0.7496\n","recommended.correction_lag_5: -0.3036\n","recommended.correction_lag_6: -0.3414\n","recommended.correction_lag_7: -0.0999\n","recommended.correction_lag_8: 0.0384\n","recommended.correction_lag_9: 0.2193\n","recommended.correction_lag_10: 0.2652\n","recommended.correction_lag_11: 0.2642\n","recommended.correction_lag_12: 0.2356\n","insulinSensitivityFactor_lag_1: 0.2691\n","insulinSensitivityFactor_lag_2: 0.2777\n","insulinSensitivityFactor_lag_3: 0.4193\n","insulinSensitivityFactor_lag_4: 0.4507\n","insulinSensitivityFactor_lag_5: 0.2247\n","insulinSensitivityFactor_lag_6: 0.1736\n","insulinSensitivityFactor_lag_7: 0.0784\n","insulinSensitivityFactor_lag_8: 0.0283\n","insulinSensitivityFactor_lag_9: -0.0751\n","insulinSensitivityFactor_lag_10: -0.0835\n","insulinSensitivityFactor_lag_11: -0.0670\n","insulinSensitivityFactor_lag_12: -0.1160\n","targetBloodGlucose_lag_1: -0.1464\n","targetBloodGlucose_lag_2: -0.1651\n","targetBloodGlucose_lag_3: -5.3086\n","targetBloodGlucose_lag_4: -4.4015\n","targetBloodGlucose_lag_5: -2.7519\n","targetBloodGlucose_lag_6: -3.2695\n","targetBloodGlucose_lag_7: -2.2033\n","targetBloodGlucose_lag_8: -1.5478\n","targetBloodGlucose_lag_9: -1.0643\n","targetBloodGlucose_lag_10: -0.8638\n","targetBloodGlucose_lag_11: -0.8363\n","targetBloodGlucose_lag_12: 0.0046\n","insulinOnBoard_lag_1: 0.5578\n","insulinOnBoard_lag_2: -0.0624\n","Intercept: 23.9974\n","Time step 6 (predicting 30 minutes ahead) - ARX RMSE: 28.1211\n","Linear Regression Coefficients (ARX Model):\n","lag_1: 2.4547\n","lag_2: -1.1457\n","lag_3: -0.5044\n","lag_4: 0.0270\n","lag_5: 0.0433\n","lag_6: -0.0531\n","lag_7: -0.0388\n","lag_8: -0.0007\n","lag_9: -0.0498\n","lag_10: -0.0131\n","lag_11: 0.0402\n","lag_12: -0.0212\n","normal: -3.1452\n","carbInput: -3.4678\n","insulinCarbRatio: -3.9341\n","bgInput: -3.5956\n","recommended.carb: -3.4115\n","recommended.net: -3.3875\n","recommended.correction: -3.3222\n","insulinSensitivityFactor: -2.5584\n","targetBloodGlucose: -2.3869\n","insulinOnBoard: -2.0250\n","normal_lag_1: -1.4642\n","normal_lag_2: -0.5362\n","normal_lag_3: 0.2234\n","normal_lag_4: 0.4942\n","normal_lag_5: 0.7586\n","normal_lag_6: 1.0406\n","normal_lag_7: 1.3886\n","normal_lag_8: 1.4822\n","normal_lag_9: 1.4465\n","normal_lag_10: 1.5533\n","normal_lag_11: 1.5002\n","normal_lag_12: 1.3846\n","carbInput_lag_1: 1.3763\n","carbInput_lag_2: 1.2352\n","carbInput_lag_3: 0.3848\n","carbInput_lag_4: 0.2767\n","carbInput_lag_5: 0.0441\n","carbInput_lag_6: 0.1184\n","carbInput_lag_7: -0.1434\n","carbInput_lag_8: -0.2096\n","carbInput_lag_9: -0.3483\n","carbInput_lag_10: -0.6926\n","carbInput_lag_11: -0.9273\n","carbInput_lag_12: -0.8168\n","insulinCarbRatio_lag_1: -0.7433\n","insulinCarbRatio_lag_2: -0.6401\n","insulinCarbRatio_lag_3: -0.0458\n","insulinCarbRatio_lag_4: -0.0690\n","insulinCarbRatio_lag_5: -0.0524\n","insulinCarbRatio_lag_6: 0.0056\n","insulinCarbRatio_lag_7: -0.0367\n","insulinCarbRatio_lag_8: -0.0819\n","insulinCarbRatio_lag_9: -0.0521\n","insulinCarbRatio_lag_10: -0.0384\n","insulinCarbRatio_lag_11: -0.0310\n","insulinCarbRatio_lag_12: 0.0018\n","bgInput_lag_1: -0.0019\n","bgInput_lag_2: 0.0111\n","bgInput_lag_3: 10.0136\n","bgInput_lag_4: 5.5332\n","bgInput_lag_5: 0.2320\n","bgInput_lag_6: -3.9677\n","bgInput_lag_7: -8.4488\n","bgInput_lag_8: -9.7892\n","bgInput_lag_9: -10.4350\n","bgInput_lag_10: -12.1367\n","bgInput_lag_11: -11.7548\n","bgInput_lag_12: -12.6729\n","recommended.carb_lag_1: -13.7726\n","recommended.carb_lag_2: -12.7829\n","recommended.carb_lag_3: -8.9646\n","recommended.carb_lag_4: -7.4256\n","recommended.carb_lag_5: -4.6670\n","recommended.carb_lag_6: -5.3062\n","recommended.carb_lag_7: -5.0727\n","recommended.carb_lag_8: -5.2436\n","recommended.carb_lag_9: -4.3591\n","recommended.carb_lag_10: -4.1331\n","recommended.carb_lag_11: -3.6471\n","recommended.carb_lag_12: -1.6701\n","recommended.net_lag_1: -0.7713\n","recommended.net_lag_2: -0.7674\n","recommended.net_lag_3: 7.8263\n","recommended.net_lag_4: 9.4464\n","recommended.net_lag_5: 6.1524\n","recommended.net_lag_6: 4.6356\n","recommended.net_lag_7: 5.8479\n","recommended.net_lag_8: 7.6368\n","recommended.net_lag_9: 5.2475\n","recommended.net_lag_10: 3.3844\n","recommended.net_lag_11: 2.6528\n","recommended.net_lag_12: 0.4470\n","recommended.correction_lag_1: -0.0932\n","recommended.correction_lag_2: -1.2949\n","recommended.correction_lag_3: -0.6389\n","recommended.correction_lag_4: -0.7367\n","recommended.correction_lag_5: -0.2822\n","recommended.correction_lag_6: -0.2944\n","recommended.correction_lag_7: 0.0254\n","recommended.correction_lag_8: 0.2106\n","recommended.correction_lag_9: 0.3889\n","recommended.correction_lag_10: 0.3531\n","recommended.correction_lag_11: 0.3956\n","recommended.correction_lag_12: 0.2693\n","insulinSensitivityFactor_lag_1: 0.3044\n","insulinSensitivityFactor_lag_2: 0.1982\n","insulinSensitivityFactor_lag_3: 0.4693\n","insulinSensitivityFactor_lag_4: 0.4969\n","insulinSensitivityFactor_lag_5: 0.2340\n","insulinSensitivityFactor_lag_6: 0.1624\n","insulinSensitivityFactor_lag_7: 0.0295\n","insulinSensitivityFactor_lag_8: -0.0237\n","insulinSensitivityFactor_lag_9: -0.1437\n","insulinSensitivityFactor_lag_10: -0.1330\n","insulinSensitivityFactor_lag_11: -0.1548\n","insulinSensitivityFactor_lag_12: -0.1425\n","targetBloodGlucose_lag_1: -0.1604\n","targetBloodGlucose_lag_2: -0.1247\n","targetBloodGlucose_lag_3: -6.7730\n","targetBloodGlucose_lag_4: -5.5770\n","targetBloodGlucose_lag_5: -3.2918\n","targetBloodGlucose_lag_6: -3.4273\n","targetBloodGlucose_lag_7: -2.2183\n","targetBloodGlucose_lag_8: -1.7462\n","targetBloodGlucose_lag_9: -1.2643\n","targetBloodGlucose_lag_10: -1.0879\n","targetBloodGlucose_lag_11: -0.9861\n","targetBloodGlucose_lag_12: 0.1614\n","insulinOnBoard_lag_1: 0.6560\n","insulinOnBoard_lag_2: 0.0222\n","Intercept: 37.2793\n","Time step 9 (predicting 45 minutes ahead) - ARX RMSE: 35.5793\n","Linear Regression Coefficients (ARX Model):\n","lag_1: 2.3220\n","lag_2: -1.1139\n","lag_3: -0.4916\n","lag_4: 0.0234\n","lag_5: 0.0480\n","lag_6: -0.0621\n","lag_7: -0.0388\n","lag_8: 0.0066\n","lag_9: -0.0630\n","lag_10: 0.0170\n","lag_11: 0.0231\n","lag_12: -0.0238\n","normal: -4.3883\n","carbInput: -4.2054\n","insulinCarbRatio: -4.3447\n","bgInput: -4.1139\n","recommended.carb: -4.1218\n","recommended.net: -4.2090\n","recommended.correction: -3.6104\n","insulinSensitivityFactor: -2.4982\n","targetBloodGlucose: -1.9808\n","insulinOnBoard: -1.6737\n","normal_lag_1: -1.1106\n","normal_lag_2: -0.4534\n","normal_lag_3: 0.8212\n","normal_lag_4: 1.0882\n","normal_lag_5: 1.2942\n","normal_lag_6: 1.5113\n","normal_lag_7: 1.8461\n","normal_lag_8: 1.9148\n","normal_lag_9: 1.8454\n","normal_lag_10: 1.8404\n","normal_lag_11: 1.8321\n","normal_lag_12: 1.7174\n","carbInput_lag_1: 1.6871\n","carbInput_lag_2: 1.4739\n","carbInput_lag_3: 0.1709\n","carbInput_lag_4: 0.0135\n","carbInput_lag_5: -0.2705\n","carbInput_lag_6: -0.1941\n","carbInput_lag_7: -0.4167\n","carbInput_lag_8: -0.4608\n","carbInput_lag_9: -0.5903\n","carbInput_lag_10: -0.8300\n","carbInput_lag_11: -1.0626\n","carbInput_lag_12: -0.9355\n","insulinCarbRatio_lag_1: -0.8543\n","insulinCarbRatio_lag_2: -0.8009\n","insulinCarbRatio_lag_3: -0.0591\n","insulinCarbRatio_lag_4: -0.0889\n","insulinCarbRatio_lag_5: -0.0880\n","insulinCarbRatio_lag_6: -0.0190\n","insulinCarbRatio_lag_7: -0.0303\n","insulinCarbRatio_lag_8: -0.0562\n","insulinCarbRatio_lag_9: -0.0439\n","insulinCarbRatio_lag_10: -0.0432\n","insulinCarbRatio_lag_11: -0.0371\n","insulinCarbRatio_lag_12: -0.0070\n","bgInput_lag_1: -0.0037\n","bgInput_lag_2: 0.0160\n","bgInput_lag_3: 5.2383\n","bgInput_lag_4: 0.3263\n","bgInput_lag_5: -4.2483\n","bgInput_lag_6: -7.9055\n","bgInput_lag_7: -12.4289\n","bgInput_lag_8: -13.6004\n","bgInput_lag_9: -14.6154\n","bgInput_lag_10: -15.3905\n","bgInput_lag_11: -15.9273\n","bgInput_lag_12: -16.7296\n","recommended.carb_lag_1: -18.4583\n","recommended.carb_lag_2: -16.2891\n","recommended.carb_lag_3: -10.3388\n","recommended.carb_lag_4: -8.6894\n","recommended.carb_lag_5: -6.3141\n","recommended.carb_lag_6: -6.4968\n","recommended.carb_lag_7: -5.9634\n","recommended.carb_lag_8: -5.6882\n","recommended.carb_lag_9: -4.4273\n","recommended.carb_lag_10: -4.1604\n","recommended.carb_lag_11: -3.5013\n","recommended.carb_lag_12: -1.5017\n","recommended.net_lag_1: 0.3056\n","recommended.net_lag_2: 0.1950\n","recommended.net_lag_3: 9.4523\n","recommended.net_lag_4: 11.1023\n","recommended.net_lag_5: 8.5850\n","recommended.net_lag_6: 6.3970\n","recommended.net_lag_7: 5.7239\n","recommended.net_lag_8: 6.2840\n","recommended.net_lag_9: 4.5615\n","recommended.net_lag_10: 3.4586\n","recommended.net_lag_11: 2.6138\n","recommended.net_lag_12: -0.0006\n","recommended.correction_lag_1: -1.8599\n","recommended.correction_lag_2: -3.5565\n","recommended.correction_lag_3: -0.5723\n","recommended.correction_lag_4: -0.5863\n","recommended.correction_lag_5: -0.1098\n","recommended.correction_lag_6: -0.1126\n","recommended.correction_lag_7: 0.1338\n","recommended.correction_lag_8: 0.3731\n","recommended.correction_lag_9: 0.4482\n","recommended.correction_lag_10: 0.3928\n","recommended.correction_lag_11: 0.3099\n","recommended.correction_lag_12: 0.2834\n","insulinSensitivityFactor_lag_1: 0.2869\n","insulinSensitivityFactor_lag_2: 0.0282\n","insulinSensitivityFactor_lag_3: 0.4475\n","insulinSensitivityFactor_lag_4: 0.4331\n","insulinSensitivityFactor_lag_5: 0.1812\n","insulinSensitivityFactor_lag_6: 0.0932\n","insulinSensitivityFactor_lag_7: -0.0258\n","insulinSensitivityFactor_lag_8: -0.1252\n","insulinSensitivityFactor_lag_9: -0.1834\n","insulinSensitivityFactor_lag_10: -0.1558\n","insulinSensitivityFactor_lag_11: -0.1159\n","insulinSensitivityFactor_lag_12: -0.1434\n","targetBloodGlucose_lag_1: -0.1527\n","targetBloodGlucose_lag_2: -0.0400\n","targetBloodGlucose_lag_3: -6.8157\n","targetBloodGlucose_lag_4: -5.5085\n","targetBloodGlucose_lag_5: -3.4845\n","targetBloodGlucose_lag_6: -3.5803\n","targetBloodGlucose_lag_7: -2.4137\n","targetBloodGlucose_lag_8: -1.9002\n","targetBloodGlucose_lag_9: -1.1109\n","targetBloodGlucose_lag_10: -0.9798\n","targetBloodGlucose_lag_11: -0.8412\n","targetBloodGlucose_lag_12: 0.3427\n","insulinOnBoard_lag_1: 1.6202\n","insulinOnBoard_lag_2: 1.3716\n","Intercept: 50.3558\n","Time step 12 (predicting 60 minutes ahead) - ARX RMSE: 41.0686\n"]}]},{"cell_type":"markdown","source":["Recursive AR Model"],"metadata":{"id":"il6JtroVCShw"}},{"cell_type":"code","source":["# Recursive forecasting function for the AR model\n","def recursive_forecast_ar_model(data, model, num_steps):\n","    # Initialize a list to store predictions\n","    predictions = []\n","\n","    # Get the last 'num_lags' lag values from the data for initial input\n","    last_known_data = data[[f'lag_{i}' for i in range(1, num_lags + 1)]].iloc[-1].values\n","\n","    # Generate recursive predictions\n","    for _ in range(num_steps):\n","        # Reshape last known data to fit model input format\n","        next_input = last_known_data.reshape(1, -1)\n","\n","        # Predict the next step\n","        next_pred = model.predict(next_input)[0]\n","        predictions.append(next_pred)\n","\n","        # Update the input data by adding the new prediction and dropping the oldest value\n","        last_known_data = np.roll(last_known_data, -1)  # Shift values left\n","        last_known_data[-1] = next_pred  # Add new prediction as the latest lag\n","\n","    return predictions"],"metadata":{"id":"HkIlwTAcIGPg","executionInfo":{"status":"ok","timestamp":1734032749392,"user_tz":300,"elapsed":55,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Function to train the AR model on 1-step-ahead predictions\n","def train_single_step_ar_model(data):\n","    # Prepare inputs (X) and target (y) for single step\n","    X = data[[f'lag_{i}' for i in range(1, num_lags + 1)]].values\n","    y = data['mg/dl'].shift(-1).dropna().values\n","    X = X[:len(y)]  # Align lengths\n","\n","    # Split into train/test\n","    X_train, X_test = X[:train_size], X[train_size:]\n","    y_train, y_test = y[:train_size], y[train_size:]\n","\n","    # Train the model\n","    model = LinearRegression()\n","    model.fit(X_train, y_train)\n","\n","    # Make predictions on the test set (1-step-ahead for evaluation)\n","    y_pred = model.predict(X_test)\n","\n","    # Calculate performance metric (RMSE)\n","    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","\n","    return model, rmse"],"metadata":{"id":"sHM5bCFsIHft","executionInfo":{"status":"ok","timestamp":1734032749392,"user_tz":300,"elapsed":50,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Train the single-step AR model and evaluate\n","single_step_model, single_step_rmse = train_single_step_ar_model(cgm_data)\n","print(f\"Single-step prediction model - RMSE: {single_step_rmse:.4f}\")\n","\n","# Perform recursive forecasting for different time steps\n","future_steps = [3, 6, 9, 12]  # 15, 30, 45, 60 minutes ahead\n","recursive_results = {}\n","\n","for step in future_steps:\n","    # Recursive prediction\n","    predictions = recursive_forecast_ar_model(cgm_data, single_step_model, step)\n","    recursive_results[f'{step*5} min ahead'] = predictions\n","    print(f\"Recursive prediction for {step*5} minutes ahead: {predictions}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ji0Xv3QuIPyE","executionInfo":{"status":"ok","timestamp":1734032749645,"user_tz":300,"elapsed":301,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}},"outputId":"e99bcdf9-018b-4153-a293-1db67458e941"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Single-step prediction model - RMSE: 10.2843\n","Recursive prediction for 15 minutes ahead: [137.6085368963603, 126.06088863669481, 125.57563251803266]\n","Recursive prediction for 30 minutes ahead: [137.6085368963603, 126.06088863669481, 125.57563251803266, 137.59798779127004, 146.8190885175337, 150.5318058177129]\n","Recursive prediction for 45 minutes ahead: [137.6085368963603, 126.06088863669481, 125.57563251803266, 137.59798779127004, 146.8190885175337, 150.5318058177129, 144.391151712002, 138.7675791148716, 128.24985582228135]\n","Recursive prediction for 60 minutes ahead: [137.6085368963603, 126.06088863669481, 125.57563251803266, 137.59798779127004, 146.8190885175337, 150.5318058177129, 144.391151712002, 138.7675791148716, 128.24985582228135, 123.83961125314762, 120.17348749872085, 130.36409348397183]\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import mean_squared_error\n","\n","# Function to calculate RMSE for each recursive forecast\n","def calculate_recursive_rmse(data, model, num_steps):\n","    # Initialize list to store RMSE values\n","    rmse_values = {}\n","\n","    # Iterate through each time step to calculate RMSE\n","    for step in num_steps:\n","        # Get the recursive predictions for the current step\n","        predictions = recursive_forecast_ar_model(data, model, step)\n","\n","        # Get the actual values corresponding to this step\n","        actual_values = data['mg/dl'].shift(-step).dropna().values[:len(predictions)]\n","\n","        # Calculate RMSE for this time step\n","        rmse = np.sqrt(mean_squared_error(actual_values, predictions))\n","        rmse_values[f'{step*5} min ahead'] = rmse\n","        print(f\"RMSE for recursive forecast {step*5} minutes ahead: {rmse:.4f}\")\n","\n","    return rmse_values\n","\n","# Calculate RMSE for recursive forecasts on the test set\n","recursive_rmse = calculate_recursive_rmse(cgm_data[train_size:], single_step_model, future_steps)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LlBYNsjVInan","executionInfo":{"status":"ok","timestamp":1734032749646,"user_tz":300,"elapsed":13,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}},"outputId":"2bcffcdc-6922-4068-ca4a-e7ac8f37c62b"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["RMSE for recursive forecast 15 minutes ahead: 43.8050\n","RMSE for recursive forecast 30 minutes ahead: 35.3008\n","RMSE for recursive forecast 45 minutes ahead: 41.9947\n","RMSE for recursive forecast 60 minutes ahead: 50.2607\n"]}]},{"cell_type":"markdown","source":["LASSO Regression"],"metadata":{"id":"NkjsoBRYIvw9"}},{"cell_type":"code","source":["from sklearn.linear_model import Lasso\n","\n","# Function to train and evaluate a Lasso regression model for a specified prediction step\n","def train_lasso_model(data, target_step, alpha=0.1, max_iter=5000):\n","    # Prepare inputs (X) and target (y)\n","    X = data[[f'lag_{i}' for i in range(1, num_lags + 1)]].values\n","    y = data['mg/dl'].shift(-target_step).dropna().values\n","    X = X[:len(y)]  # Align lengths\n","\n","    # Split into train/test\n","    X_train, X_test = X[:train_size], X[train_size:]\n","    y_train, y_test = y[:train_size], y[train_size:]\n","\n","    # Train the Lasso model with specified alpha (regularization strength)\n","    lasso_model = Lasso(alpha=alpha, max_iter=max_iter)\n","    lasso_model.fit(X_train, y_train)\n","\n","    # Make predictions\n","    y_pred = lasso_model.predict(X_test)\n","\n","    # Calculate performance metric (RMSE)\n","    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","\n","    return lasso_model, rmse"],"metadata":{"id":"W0vXtL8pM4Op","executionInfo":{"status":"ok","timestamp":1734032749646,"user_tz":300,"elapsed":6,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Train and evaluate Lasso models for different time steps\n","lasso_results = {}\n","for step in time_steps:\n","    model, rmse = train_lasso_model(cgm_data, step, alpha=0.1, max_iter=5000)\n","    lasso_results[f'{step*5} min ahead'] = {'Model': model, 'RMSE': rmse}\n","    print(f\"Lasso regression for {step*5} minutes ahead - RMSE: {rmse:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"btYD6roIM5XK","executionInfo":{"status":"ok","timestamp":1734032861953,"user_tz":300,"elapsed":112312,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}},"outputId":"94503521-509f-4acd-fbda-a893d4967a1c"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Lasso regression for 15 minutes ahead - RMSE: 18.3468\n","Lasso regression for 30 minutes ahead - RMSE: 27.9009\n","Lasso regression for 45 minutes ahead - RMSE: 35.2395\n","Lasso regression for 60 minutes ahead - RMSE: 40.6371\n"]}]},{"cell_type":"markdown","source":["Ridge Regression"],"metadata":{"id":"3jrB_xynPg3_"}},{"cell_type":"code","source":["from sklearn.linear_model import Ridge\n","\n","# Function to train and evaluate a Ridge regression model for a specified prediction step\n","def train_ridge_model(data, target_step, alpha=1.0):\n","    # Prepare inputs (X) and target (y)\n","    X = data[[f'lag_{i}' for i in range(1, num_lags + 1)]].values\n","    y = data['mg/dl'].shift(-target_step).dropna().values\n","    X = X[:len(y)]  # Align lengths\n","\n","    # Split into train/test\n","    X_train, X_test = X[:train_size], X[train_size:]\n","    y_train, y_test = y[:train_size], y[train_size:]\n","\n","    # Train the Ridge model with specified alpha (regularization strength)\n","    ridge_model = Ridge(alpha=alpha)\n","    ridge_model.fit(X_train, y_train)\n","\n","    # Make predictions\n","    y_pred = ridge_model.predict(X_test)\n","\n","    # Calculate performance metric (RMSE)\n","    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","\n","    return ridge_model, rmse\n","\n","# Train and evaluate Ridge models for different time steps\n","ridge_results = {}\n","alpha_value = 1.0  # Adjust alpha as needed for regularization strength\n","for step in time_steps:\n","    model, rmse = train_ridge_model(cgm_data, step, alpha=alpha_value)\n","    ridge_results[f'{step*5} min ahead'] = {'Model': model, 'RMSE': rmse}\n","    print(f\"Ridge regression for {step*5} minutes ahead - RMSE: {rmse:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GyVdNSkKSL5j","executionInfo":{"status":"ok","timestamp":1734032862227,"user_tz":300,"elapsed":312,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}},"outputId":"f1843651-38e3-4026-fbac-d63386d79b4f"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Ridge regression for 15 minutes ahead - RMSE: 18.3526\n","Ridge regression for 30 minutes ahead - RMSE: 27.9059\n","Ridge regression for 45 minutes ahead - RMSE: 35.2443\n","Ridge regression for 60 minutes ahead - RMSE: 40.6424\n"]}]},{"cell_type":"markdown","source":["Elastic Net Regression"],"metadata":{"id":"l7xmEKZHYzVa"}},{"cell_type":"code","source":["from sklearn.linear_model import ElasticNet\n","\n","# Function to train and evaluate ElasticNet model\n","def train_elastic_net_model(data, target_step, alpha=1.0, l1_ratio=0.5):\n","    # Prepare inputs (X) and target (y)\n","    X = data[[f'lag_{i}' for i in range(1, num_lags + 1)]].values\n","    y = data['mg/dl'].shift(-target_step).dropna().values\n","    X = X[:len(y)]  # Align lengths\n","\n","    # Split into train/test\n","    X_train, X_test = X[:train_size], X[train_size:]\n","    y_train, y_test = y[:train_size], y[train_size:]\n","\n","    # Train the ElasticNet model\n","    elastic_net_model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n","    elastic_net_model.fit(X_train, y_train)\n","\n","    # Make predictions\n","    y_pred = elastic_net_model.predict(X_test)\n","\n","    # Calculate performance metric (RMSE)\n","    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","\n","    return elastic_net_model, rmse\n","\n","# Train and evaluate ElasticNet models for different time steps\n","elastic_net_results = {}\n","alpha_value = 1.0  # Regularization strength (larger values => more regularization)\n","l1_ratio_value = 0.5  # Mix ratio between Lasso (L1) and Ridge (L2) regularization\n","for step in time_steps:\n","    model, rmse = train_elastic_net_model(cgm_data, step, alpha=alpha_value, l1_ratio=l1_ratio_value)\n","    elastic_net_results[f'{step*5} min ahead'] = {'Model': model, 'RMSE': rmse}\n","    print(f\"ElasticNet for {step*5} minutes ahead - RMSE: {rmse:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xelNG6-fY-hH","executionInfo":{"status":"ok","timestamp":1734032913030,"user_tz":300,"elapsed":50808,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}},"outputId":"1888f82f-41a5-4fea-a7b9-166d7974d8ad"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["ElasticNet for 15 minutes ahead - RMSE: 18.3054\n","ElasticNet for 30 minutes ahead - RMSE: 27.8663\n","ElasticNet for 45 minutes ahead - RMSE: 35.2043\n","ElasticNet for 60 minutes ahead - RMSE: 40.6024\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.166e+05, tolerance: 1.092e+05\n","  model = cd_fast.enet_coordinate_descent(\n"]}]},{"cell_type":"markdown","source":["Huber"],"metadata":{"id":"dElBbo6IZGGM"}},{"cell_type":"code","source":["from sklearn.linear_model import HuberRegressor\n","\n","# Function to train and evaluate Huber regression model\n","def train_huber_model(data, target_step, epsilon=1.35):\n","    # Prepare inputs (X) and target (y)\n","    X = data[[f'lag_{i}' for i in range(1, num_lags + 1)]].values\n","    y = data['mg/dl'].shift(-target_step).dropna().values\n","    X = X[:len(y)]  # Align lengths\n","\n","    # Split into train/test\n","    X_train, X_test = X[:train_size], X[train_size:]\n","    y_train, y_test = y[:train_size], y[train_size:]\n","\n","    # Train the Huber regression model\n","    huber_model = HuberRegressor(epsilon=epsilon, max_iter=1000)\n","    huber_model.fit(X_train, y_train)\n","\n","    # Make predictions\n","    y_pred = huber_model.predict(X_test)\n","\n","    # Calculate performance metric (RMSE)\n","    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","\n","    return huber_model, rmse\n","\n","# Train and evaluate Huber models for different time steps\n","huber_results = {}\n","epsilon_value = 1.35  # Huber loss function parameter (controls the threshold between quadratic and linear loss)\n","for step in time_steps:\n","    model, rmse = train_huber_model(cgm_data, step, epsilon=epsilon_value)\n","    huber_results[f'{step*5} min ahead'] = {'Model': model, 'RMSE': rmse}\n","    print(f\"Huber for {step*5} minutes ahead - RMSE: {rmse:.4f}\")\n"],"metadata":{"id":"JaMt0glzZLSK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734033068953,"user_tz":300,"elapsed":155933,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}},"outputId":"16b1dcaa-2ad8-4818-9ba4-3edff26067de"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Huber for 15 minutes ahead - RMSE: 19.6341\n","Huber for 30 minutes ahead - RMSE: 29.1687\n","Huber for 45 minutes ahead - RMSE: 36.5450\n","Huber for 60 minutes ahead - RMSE: 41.8928\n"]}]},{"cell_type":"markdown","source":["Random Forest"],"metadata":{"id":"_GyZIr2Ca_Mo"}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_squared_error\n","\n","# Function to train and evaluate Random Forest model\n","def train_rf_model(data, target_step, n_estimators=100, max_depth=None, random_state=42):\n","    # Prepare inputs (X) and target (y)\n","    X = data[[f'lag_{i}' for i in range(1, num_lags + 1)]].values\n","    y = data['mg/dl'].shift(-target_step).dropna().values\n","    X = X[:len(y)]  # Align lengths\n","\n","    # Split into train/test\n","    X_train, X_test = X[:train_size], X[train_size:]\n","    y_train, y_test = y[:train_size], y[train_size:]\n","\n","    # Train the Random Forest model\n","    rf_model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=random_state)\n","    rf_model.fit(X_train, y_train)\n","\n","    # Make predictions\n","    y_pred = rf_model.predict(X_test)\n","\n","    # Calculate performance metric (RMSE)\n","    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","\n","    return rf_model, rmse\n","\n","# Train and evaluate Random Forest models for different time steps\n","rf_results = {}\n","for step in time_steps:\n","    model, rmse = train_rf_model(cgm_data, step, n_estimators=100, max_depth=10)\n","    rf_results[f'{step*5} min ahead'] = {'Model': model, 'RMSE': rmse}\n","    print(f\"Random Forest for {step*5} minutes ahead - RMSE: {rmse:.4f}\")\n"],"metadata":{"id":"ccFkUnHchZzE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734033741683,"user_tz":300,"elapsed":672777,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}},"outputId":"17916b72-b01f-4535-cbd3-63a36a36662c"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Random Forest for 15 minutes ahead - RMSE: 17.3849\n","Random Forest for 30 minutes ahead - RMSE: 26.8599\n","Random Forest for 45 minutes ahead - RMSE: 34.3046\n","Random Forest for 60 minutes ahead - RMSE: 39.8350\n"]}]},{"cell_type":"markdown","source":["XGBoost"],"metadata":{"id":"opeXoGyzbAGT"}},{"cell_type":"code","source":["import xgboost as xgb\n","from sklearn.metrics import mean_squared_error\n","\n","# Function to train and evaluate XGBoost model\n","def train_xgb_model(data, target_step, num_boost_round=100, learning_rate=0.1, max_depth=30, random_state=42):\n","    # Prepare inputs (X) and target (y)\n","    X = data[[f'lag_{i}' for i in range(1, num_lags + 1)]].values\n","    y = data['mg/dl'].shift(-target_step).dropna().values\n","    X = X[:len(y)]  # Align lengths\n","\n","    # Split into train/test\n","    X_train, X_test = X[:train_size], X[train_size:]\n","    y_train, y_test = y[:train_size], y[train_size:]\n","\n","    # Create DMatrix for XGBoost\n","    dtrain = xgb.DMatrix(X_train, label=y_train)\n","    dtest = xgb.DMatrix(X_test, label=y_test)\n","\n","    # Set parameters for XGBoost\n","    params = {\n","        'objective': 'reg:squarederror',  # Regression task (squared error loss)\n","        'eval_metric': 'rmse',            # Metric to evaluate model\n","        'max_depth': max_depth,           # Depth of the trees\n","        'learning_rate': learning_rate,  # Step size shrinkage\n","        'random_state': random_state,    # For reproducibility\n","    }\n","\n","    # Train the XGBoost model\n","    model = xgb.train(params, dtrain, num_boost_round=num_boost_round)\n","\n","    # Make predictions\n","    y_pred = model.predict(dtest)\n","\n","    # Calculate performance metric (RMSE)\n","    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","\n","    return model, rmse\n","\n","# Train and evaluate XGBoost models for different time steps\n","xgb_results = {}\n","for step in time_steps:\n","    model, rmse = train_xgb_model(cgm_data, step, num_boost_round=100, learning_rate=0.1, max_depth=10)\n","    xgb_results[f'{step*5} min ahead'] = {'Model': model, 'RMSE': rmse}\n","    print(f\"XGBoost for {step*5} minutes ahead - RMSE: {rmse:.4f}\")\n"],"metadata":{"id":"qFksTsoXoejo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734033772192,"user_tz":300,"elapsed":30552,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}},"outputId":"cbe09fd6-bdf7-4d8a-a1b4-7f681d5f6cdf"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["XGBoost for 15 minutes ahead - RMSE: 17.5314\n","XGBoost for 30 minutes ahead - RMSE: 26.9360\n","XGBoost for 45 minutes ahead - RMSE: 34.3596\n","XGBoost for 60 minutes ahead - RMSE: 39.9721\n"]}]},{"cell_type":"code","source":["import xgboost as xgb\n","from sklearn.metrics import mean_squared_error\n","import numpy as np\n","\n","# Function to train and evaluate XGBoost model with ARX features\n","def train_xgb_arx_model(data, target_step, num_boost_round=100, learning_rate=0.1, max_depth=10, random_state=42):\n","    # Prepare inputs (X) and target (y)\n","    # Use all lagged features (CGM + Bolus variables)\n","    feature_columns = [col for col in data.columns if col.startswith('lag_') or '_lag_' in col]\n","    X = data[feature_columns].values\n","    y = data['mg/dl'].shift(-target_step).dropna().values\n","    X = X[:len(y)]  # Align lengths\n","\n","    # Split into train/test\n","    X_train, X_test = X[:train_size], X[train_size:]\n","    y_train, y_test = y[:train_size], y[train_size:]\n","\n","    # Create DMatrix for XGBoost\n","    dtrain = xgb.DMatrix(X_train, label=y_train)\n","    dtest = xgb.DMatrix(X_test, label=y_test)\n","\n","    # Set parameters for XGBoost\n","    params = {\n","        'objective': 'reg:squarederror',  # Regression task (squared error loss)\n","        'eval_metric': 'rmse',            # Metric to evaluate model\n","        'max_depth': max_depth,           # Depth of the trees\n","        'learning_rate': learning_rate,   # Step size shrinkage\n","        'random_state': random_state,     # For reproducibility\n","    }\n","\n","    # Train the XGBoost model\n","    model = xgb.train(params, dtrain, num_boost_round=num_boost_round)\n","\n","    # Make predictions\n","    y_pred = model.predict(dtest)\n","\n","    # Calculate performance metric (RMSE)\n","    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","\n","    return model, rmse\n","\n","# Train and evaluate XGBoost models for different time steps\n","xgb_arx_results = {}\n","for step in time_steps:\n","    model, rmse = train_xgb_arx_model(merged_data, step, num_boost_round=100, learning_rate=0.1, max_depth=10)\n","    xgb_arx_results[f'{step*5} min ahead'] = {'Model': model, 'RMSE': rmse}\n","    print(f\"XGBoost (ARX) for {step*5} minutes ahead - RMSE: {rmse:.4f}\")"],"metadata":{"id":"4rX7CK7TBFPM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734033905329,"user_tz":300,"elapsed":133174,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}},"outputId":"4012ce94-15cd-4804-d5fe-cb9948ff161b"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["XGBoost (ARX) for 15 minutes ahead - RMSE: 17.5089\n","XGBoost (ARX) for 30 minutes ahead - RMSE: 26.9296\n","XGBoost (ARX) for 45 minutes ahead - RMSE: 34.3448\n","XGBoost (ARX) for 60 minutes ahead - RMSE: 39.9180\n"]}]}]}