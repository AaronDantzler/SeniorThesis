{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMAux1ArNuN4pwrVCvKE5S8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OQlCqHTP9N4F","executionInfo":{"status":"ok","timestamp":1734032866630,"user_tz":300,"elapsed":37952,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}},"outputId":"284c3582-e05a-4466-f77b-d6644cc53d49"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["Autoregressive Linear Regression on just Blood Glucose"],"metadata":{"id":"tqnTDSRvEHjU"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import train_test_split\n","\n","# Load the data\n","file_path = '/content/drive/My Drive/Thesis/Subject5.xlsx'\n","cgm_data = pd.read_excel(file_path, sheet_name='CGM')"],"metadata":{"id":"ud1OmyUu2v7P","executionInfo":{"status":"ok","timestamp":1734032891748,"user_tz":300,"elapsed":25128,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Preprocess - Round to nearest 5 minutes\n","cgm_data['date'] = pd.to_datetime(cgm_data['date']).dt.round('5min')\n","\n","# Filter out rows where mg/dl is > 400 or missing values\n","cgm_data = cgm_data[cgm_data['mg/dl'] <= 400].dropna(subset=['mg/dl'])\n","\n","# Drop duplicates and sort\n","cgm_data = cgm_data.drop_duplicates(subset='date').reset_index(drop=True)\n","cgm_data = cgm_data.sort_values(by='date').reset_index(drop=True)"],"metadata":{"id":"douYzyaW2xjy","executionInfo":{"status":"ok","timestamp":1734032891841,"user_tz":300,"elapsed":109,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Generate AR Features (using past 12 readings as input)\n","num_lags = 12 # Using the past 12 values\n","for lag in range(1, num_lags + 1):\n","    cgm_data[f'lag_{lag}'] = cgm_data['mg/dl'].shift(lag)\n","\n","cgm_data = cgm_data.dropna().reset_index(drop=True)"],"metadata":{"id":"CRxaWkzv2x6u","executionInfo":{"status":"ok","timestamp":1734032892087,"user_tz":300,"elapsed":249,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Split into train/test (80% train, 20% test by time order)\n","train_size = int(len(cgm_data) * 0.8)\n","train_data = cgm_data[:train_size]\n","test_data = cgm_data[train_size:]"],"metadata":{"id":"OkoX5i1J2002","executionInfo":{"status":"ok","timestamp":1734032892089,"user_tz":300,"elapsed":22,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Define function to train and evaluate for different time steps\n","def train_ar_model(data, target_step):\n","    # Prepare inputs (X) and target (y)\n","    X = data[[f'lag_{i}' for i in range(1, num_lags + 1)]].values\n","    y = data['mg/dl'].shift(-target_step).dropna().values\n","    X = X[:len(y)]  # Align lengths\n","\n","    # Split into train/test\n","    X_train, X_test = X[:train_size], X[train_size:]\n","    y_train, y_test = y[:train_size], y[train_size:]\n","\n","    # Train the model\n","    model = LinearRegression()\n","    model.fit(X_train, y_train)\n","\n","    # Make predictions\n","    y_pred = model.predict(X_test)\n","\n","    # Calculate performance metric (RMSE)\n","    rmse = np.sqrt(mean_squared_error(y_test, y_pred))  # Use np.sqrt on MSE\n","\n","    # Display the coefficients\n","    coefficients = model.coef_\n","    intercept = model.intercept_\n","\n","    print(\"Linear Regression Coefficients (lags):\")\n","    for i, coef in enumerate(coefficients, start=1):\n","      print(f\"Lag {i}: {coef:.4f}\")\n","    print(f\"Intercept: {intercept:.4f}\")\n","\n","    return model, rmse"],"metadata":{"id":"x97E22Mm22Zs","executionInfo":{"status":"ok","timestamp":1734032892090,"user_tz":300,"elapsed":18,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Train models for different time step targets and evaluate\n","time_steps = [3, 6, 9, 12]  # Corresponding to 15, 30, 45, 60 minutes\n","results = {}\n","\n","for step in time_steps:\n","    model, rmse = train_ar_model(cgm_data, step)\n","    results[f'{step*5} min ahead'] = {'Model': model, 'RMSE': rmse}\n","    print(f\"Time step {step} (predicting {step*5} minutes ahead) - RMSE: {rmse:.4f}\")\n","\n","# Results dictionary now contains trained models and RMSE for each time target"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0wp2DlsI24Qc","executionInfo":{"status":"ok","timestamp":1734032892854,"user_tz":300,"elapsed":780,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}},"outputId":"4afc01e0-adca-4193-94fe-84669e8c995f"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Linear Regression Coefficients (lags):\n","Lag 1: 1.5462\n","Lag 2: -0.2692\n","Lag 3: -0.1585\n","Lag 4: -0.0720\n","Lag 5: -0.0106\n","Lag 6: -0.0330\n","Lag 7: -0.0286\n","Lag 8: -0.0141\n","Lag 9: -0.0117\n","Lag 10: -0.0025\n","Lag 11: 0.0044\n","Lag 12: -0.0196\n","Intercept: 12.5374\n","Time step 3 (predicting 15 minutes ahead) - RMSE: 16.4981\n","Linear Regression Coefficients (lags):\n","Lag 1: 1.6627\n","Lag 2: -0.3356\n","Lag 3: -0.2005\n","Lag 4: -0.0979\n","Lag 5: -0.0248\n","Lag 6: -0.0476\n","Lag 7: -0.0303\n","Lag 8: -0.0172\n","Lag 9: -0.0123\n","Lag 10: -0.0086\n","Lag 11: 0.0078\n","Lag 12: -0.0309\n","Intercept: 24.4628\n","Time step 6 (predicting 30 minutes ahead) - RMSE: 24.4678\n","Linear Regression Coefficients (lags):\n","Lag 1: 1.6676\n","Lag 2: -0.3637\n","Lag 3: -0.2199\n","Lag 4: -0.1017\n","Lag 5: -0.0295\n","Lag 6: -0.0502\n","Lag 7: -0.0386\n","Lag 8: -0.0177\n","Lag 9: -0.0124\n","Lag 10: -0.0024\n","Lag 11: 0.0126\n","Lag 12: -0.0488\n","Intercept: 37.0636\n","Time step 9 (predicting 45 minutes ahead) - RMSE: 31.1743\n","Linear Regression Coefficients (lags):\n","Lag 1: 1.6085\n","Lag 2: -0.3631\n","Lag 3: -0.2185\n","Lag 4: -0.1086\n","Lag 5: -0.0304\n","Lag 6: -0.0506\n","Lag 7: -0.0340\n","Lag 8: -0.0167\n","Lag 9: -0.0074\n","Lag 10: -0.0012\n","Lag 11: 0.0120\n","Lag 12: -0.0643\n","Intercept: 49.6437\n","Time step 12 (predicting 60 minutes ahead) - RMSE: 36.8401\n"]}]},{"cell_type":"markdown","source":["ARX Model with Blood Glucose and Bolus Data"],"metadata":{"id":"g3a743rVoLM7"}},{"cell_type":"code","source":["# Load Bolus data\n","bolus_data = pd.read_excel(file_path, sheet_name='Bolus')\n","\n","# Preprocess Bolus data - Round to nearest 5 minutes and fill missing values with 0\n","bolus_data['date'] = pd.to_datetime(bolus_data['date']).dt.round('5min')\n","bolus_data = bolus_data.fillna(0)  # Set missing values to 0\n","\n","# Merge Bolus data with CGM data on date\n","merged_data = pd.merge(cgm_data, bolus_data, on='date', how='left').fillna(0)  # Fill missing values after merge\n","\n","# Generate lag features for Bolus variables\n","bolus_vars = ['normal', 'carbInput', 'insulinCarbRatio', 'bgInput', 'recommended.carb', 'recommended.net',\n","              'recommended.correction', 'insulinSensitivityFactor', 'targetBloodGlucose', 'insulinOnBoard']\n","\n","for var in bolus_vars:\n","    for lag in range(1, num_lags + 1):\n","        merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","\n","# Drop rows with NaNs introduced by shifting\n","merged_data = merged_data.dropna().reset_index(drop=True)\n","\n","# Update train/test split based on merged data\n","train_data = merged_data[:train_size]\n","test_data = merged_data[train_size:]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Jt4GA81BcX0","executionInfo":{"status":"ok","timestamp":1734032896722,"user_tz":300,"elapsed":3874,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}},"outputId":"964d19c8-01c5-4f83-9a9c-22074162fd5f"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n","<ipython-input-8-04aca2ebd074>:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  merged_data[f'{var}_lag_{lag}'] = merged_data[var].shift(lag)\n"]}]},{"cell_type":"code","source":["# Modify train_ar_model function to include all lagged features\n","def train_arx_model(data, target_step):\n","    # Prepare inputs (X) - using lag features from both mg/dl and Bolus data\n","    lag_columns = [f'lag_{i}' for i in range(1, num_lags + 1)] + \\\n","                  [f'{var}_lag_{i}' for var in bolus_vars for i in range(1, num_lags + 1)]\n","    X = data[lag_columns].values\n","    y = data['mg/dl'].shift(-target_step).dropna().values\n","    X = X[:len(y)]  # Align lengths\n","\n","    # Split into train/test\n","    X_train, X_test = X[:train_size], X[train_size:]\n","    y_train, y_test = y[:train_size], y[train_size:]\n","\n","    # Train the model\n","    model = LinearRegression()\n","    model.fit(X_train, y_train)\n","\n","    # Make predictions\n","    y_pred = model.predict(X_test)\n","\n","    # Calculate performance metric (RMSE)\n","    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","\n","    # Extract coefficients and intercept\n","    coefficients = model.coef_\n","    intercept = model.intercept_\n","\n","    # Display the coefficients\n","    print(\"Linear Regression Coefficients (ARX Model):\")\n","    feature_names = merged_data.drop(columns=['date', 'mg/dl']).columns\n","    for feature, coef in zip(feature_names, coefficients):\n","      print(f\"{feature}: {coef:.4f}\")\n","    print(f\"Intercept: {intercept:.4f}\")\n","\n","    return model, rmse"],"metadata":{"id":"ZAZtpnsdBmZ_","executionInfo":{"status":"ok","timestamp":1734032896723,"user_tz":300,"elapsed":15,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Train ARX models for different time steps and evaluate\n","results_arx = {}\n","for step in time_steps:\n","    model, rmse = train_arx_model(merged_data, step)\n","    results_arx[f'{step*5} min ahead'] = {'Model': model, 'RMSE': rmse}\n","    print(f\"Time step {step} (predicting {step*5} minutes ahead) - ARX RMSE: {rmse:.4f}\")"],"metadata":{"id":"5LG4pUQsB1R-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734032918552,"user_tz":300,"elapsed":21842,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}},"outputId":"5fe1a111-d4c2-4522-e847-78a9af1a657b"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Linear Regression Coefficients (ARX Model):\n","lag_1: 1.5389\n","lag_2: -0.2670\n","lag_3: -0.1575\n","lag_4: -0.0712\n","lag_5: -0.0102\n","lag_6: -0.0328\n","lag_7: -0.0285\n","lag_8: -0.0138\n","lag_9: -0.0112\n","lag_10: -0.0025\n","lag_11: 0.0048\n","lag_12: -0.0186\n","normal: 1.5214\n","carbInput: 1.4959\n","insulinCarbRatio: 1.4994\n","bgInput: 1.3765\n","recommended.carb: 1.0985\n","recommended.net: 0.9547\n","recommended.correction: 0.6918\n","insulinSensitivityFactor: 0.3898\n","targetBloodGlucose: 0.3202\n","insulinOnBoard: 0.2186\n","normal_lag_1: 0.4171\n","normal_lag_2: 0.5285\n","normal_lag_3: -0.0086\n","normal_lag_4: 0.0493\n","normal_lag_5: 0.0188\n","normal_lag_6: 0.0201\n","normal_lag_7: -0.2552\n","normal_lag_8: -0.4508\n","normal_lag_9: -0.4014\n","normal_lag_10: -0.5338\n","normal_lag_11: -0.2631\n","normal_lag_12: -0.3205\n","carbInput_lag_1: -0.3590\n","carbInput_lag_2: -0.2066\n","carbInput_lag_3: 0.1586\n","carbInput_lag_4: 0.6512\n","carbInput_lag_5: 0.4744\n","carbInput_lag_6: 0.5592\n","carbInput_lag_7: 0.5658\n","carbInput_lag_8: 0.5098\n","carbInput_lag_9: 0.4657\n","carbInput_lag_10: 0.0495\n","carbInput_lag_11: -0.2911\n","carbInput_lag_12: -0.2642\n","insulinCarbRatio_lag_1: -0.4778\n","insulinCarbRatio_lag_2: 0.0386\n","insulinCarbRatio_lag_3: -0.0454\n","insulinCarbRatio_lag_4: -0.0373\n","insulinCarbRatio_lag_5: -0.0292\n","insulinCarbRatio_lag_6: -0.0017\n","insulinCarbRatio_lag_7: 0.0020\n","insulinCarbRatio_lag_8: -0.0008\n","insulinCarbRatio_lag_9: 0.0027\n","insulinCarbRatio_lag_10: -0.0194\n","insulinCarbRatio_lag_11: -0.0265\n","insulinCarbRatio_lag_12: -0.0211\n","bgInput_lag_1: -0.0163\n","bgInput_lag_2: -0.0088\n","bgInput_lag_3: 5.8133\n","bgInput_lag_4: 3.8329\n","bgInput_lag_5: 0.2110\n","bgInput_lag_6: -0.9469\n","bgInput_lag_7: 0.3380\n","bgInput_lag_8: 2.1282\n","bgInput_lag_9: 4.0217\n","bgInput_lag_10: 5.6097\n","bgInput_lag_11: 3.7149\n","bgInput_lag_12: 2.2211\n","recommended.carb_lag_1: 2.8598\n","recommended.carb_lag_2: 1.1482\n","recommended.carb_lag_3: -7.2701\n","recommended.carb_lag_4: -5.4372\n","recommended.carb_lag_5: -1.1545\n","recommended.carb_lag_6: 0.1172\n","recommended.carb_lag_7: 1.3155\n","recommended.carb_lag_8: 0.5678\n","recommended.carb_lag_9: -1.9955\n","recommended.carb_lag_10: -2.4521\n","recommended.carb_lag_11: -2.4637\n","recommended.carb_lag_12: -0.6896\n","recommended.net_lag_1: -0.7578\n","recommended.net_lag_2: -0.4723\n","recommended.net_lag_3: 7.0717\n","recommended.net_lag_4: 5.1751\n","recommended.net_lag_5: 0.1631\n","recommended.net_lag_6: -3.0131\n","recommended.net_lag_7: -3.4690\n","recommended.net_lag_8: -2.4823\n","recommended.net_lag_9: 0.1196\n","recommended.net_lag_10: 1.9415\n","recommended.net_lag_11: 2.1025\n","recommended.net_lag_12: 0.1028\n","recommended.correction_lag_1: -0.2885\n","recommended.correction_lag_2: -0.5314\n","recommended.correction_lag_3: -0.0371\n","recommended.correction_lag_4: -0.0154\n","recommended.correction_lag_5: -0.0246\n","recommended.correction_lag_6: -0.0227\n","recommended.correction_lag_7: -0.0541\n","recommended.correction_lag_8: -0.0911\n","recommended.correction_lag_9: -0.0702\n","recommended.correction_lag_10: -0.0968\n","recommended.correction_lag_11: -0.0708\n","recommended.correction_lag_12: -0.0535\n","insulinSensitivityFactor_lag_1: -0.0627\n","insulinSensitivityFactor_lag_2: -0.0452\n","insulinSensitivityFactor_lag_3: 0.0604\n","insulinSensitivityFactor_lag_4: 0.0267\n","insulinSensitivityFactor_lag_5: 0.0340\n","insulinSensitivityFactor_lag_6: 0.0293\n","insulinSensitivityFactor_lag_7: 0.0130\n","insulinSensitivityFactor_lag_8: 0.0181\n","insulinSensitivityFactor_lag_9: 0.0140\n","insulinSensitivityFactor_lag_10: 0.0360\n","insulinSensitivityFactor_lag_11: 0.0490\n","insulinSensitivityFactor_lag_12: 0.0481\n","targetBloodGlucose_lag_1: 0.0486\n","targetBloodGlucose_lag_2: 0.0154\n","targetBloodGlucose_lag_3: -4.0747\n","targetBloodGlucose_lag_4: -2.7666\n","targetBloodGlucose_lag_5: 1.1957\n","targetBloodGlucose_lag_6: 2.2917\n","targetBloodGlucose_lag_7: 2.5964\n","targetBloodGlucose_lag_8: 2.2003\n","targetBloodGlucose_lag_9: -0.4071\n","targetBloodGlucose_lag_10: -0.7171\n","targetBloodGlucose_lag_11: -0.7354\n","targetBloodGlucose_lag_12: 0.8235\n","insulinOnBoard_lag_1: 1.4870\n","insulinOnBoard_lag_2: 1.4049\n","Intercept: 12.3327\n","Time step 3 (predicting 15 minutes ahead) - ARX RMSE: 16.3732\n","Linear Regression Coefficients (ARX Model):\n","lag_1: 1.6523\n","lag_2: -0.3328\n","lag_3: -0.1991\n","lag_4: -0.0968\n","lag_5: -0.0241\n","lag_6: -0.0474\n","lag_7: -0.0296\n","lag_8: -0.0169\n","lag_9: -0.0115\n","lag_10: -0.0084\n","lag_11: 0.0084\n","lag_12: -0.0296\n","normal: 2.6818\n","carbInput: 2.5367\n","insulinCarbRatio: 2.4631\n","bgInput: 2.0255\n","recommended.carb: 1.5485\n","recommended.net: 1.2309\n","recommended.correction: 1.0925\n","insulinSensitivityFactor: 0.8672\n","targetBloodGlucose: 0.8406\n","insulinOnBoard: 0.6137\n","normal_lag_1: 0.8356\n","normal_lag_2: 0.8294\n","normal_lag_3: -0.0411\n","normal_lag_4: -0.1994\n","normal_lag_5: -0.3022\n","normal_lag_6: -0.3707\n","normal_lag_7: -0.5628\n","normal_lag_8: -0.6553\n","normal_lag_9: -0.7723\n","normal_lag_10: -0.8855\n","normal_lag_11: -0.4873\n","normal_lag_12: -0.2092\n","carbInput_lag_1: -0.1074\n","carbInput_lag_2: 0.0999\n","carbInput_lag_3: 0.6322\n","carbInput_lag_4: 1.2236\n","carbInput_lag_5: 0.8600\n","carbInput_lag_6: 0.9286\n","carbInput_lag_7: 0.5325\n","carbInput_lag_8: 0.2419\n","carbInput_lag_9: 0.0413\n","carbInput_lag_10: -0.1310\n","carbInput_lag_11: -0.1440\n","carbInput_lag_12: -0.0344\n","insulinCarbRatio_lag_1: -0.1100\n","insulinCarbRatio_lag_2: 0.5539\n","insulinCarbRatio_lag_3: -0.0514\n","insulinCarbRatio_lag_4: -0.0367\n","insulinCarbRatio_lag_5: -0.0297\n","insulinCarbRatio_lag_6: -0.0086\n","insulinCarbRatio_lag_7: -0.0165\n","insulinCarbRatio_lag_8: -0.0184\n","insulinCarbRatio_lag_9: -0.0168\n","insulinCarbRatio_lag_10: -0.0268\n","insulinCarbRatio_lag_11: -0.0364\n","insulinCarbRatio_lag_12: -0.0363\n","bgInput_lag_1: -0.0421\n","bgInput_lag_2: -0.0335\n","bgInput_lag_3: 5.3983\n","bgInput_lag_4: 4.1040\n","bgInput_lag_5: 3.1354\n","bgInput_lag_6: 3.3090\n","bgInput_lag_7: 3.7891\n","bgInput_lag_8: 4.1265\n","bgInput_lag_9: 6.9987\n","bgInput_lag_10: 9.1902\n","bgInput_lag_11: 4.9865\n","bgInput_lag_12: 1.4892\n","recommended.carb_lag_1: 2.0686\n","recommended.carb_lag_2: -1.0043\n","recommended.carb_lag_3: -6.9968\n","recommended.carb_lag_4: -4.4624\n","recommended.carb_lag_5: -2.4173\n","recommended.carb_lag_6: -2.1176\n","recommended.carb_lag_7: -0.5370\n","recommended.carb_lag_8: -0.4780\n","recommended.carb_lag_9: -2.8926\n","recommended.carb_lag_10: -4.2351\n","recommended.carb_lag_11: -3.0145\n","recommended.carb_lag_12: -1.6276\n","recommended.net_lag_1: -2.9805\n","recommended.net_lag_2: -1.6832\n","recommended.net_lag_3: 4.9008\n","recommended.net_lag_4: 2.0645\n","recommended.net_lag_5: -0.6252\n","recommended.net_lag_6: -2.1043\n","recommended.net_lag_7: -2.3852\n","recommended.net_lag_8: -2.3469\n","recommended.net_lag_9: 0.1718\n","recommended.net_lag_10: 2.4495\n","recommended.net_lag_11: 1.8448\n","recommended.net_lag_12: 0.5305\n","recommended.correction_lag_1: 2.0873\n","recommended.correction_lag_2: 1.1930\n","recommended.correction_lag_3: -0.0716\n","recommended.correction_lag_4: -0.0660\n","recommended.correction_lag_5: -0.0877\n","recommended.correction_lag_6: -0.0948\n","recommended.correction_lag_7: -0.1250\n","recommended.correction_lag_8: -0.1398\n","recommended.correction_lag_9: -0.1412\n","recommended.correction_lag_10: -0.1559\n","recommended.correction_lag_11: -0.1162\n","recommended.correction_lag_12: -0.0807\n","insulinSensitivityFactor_lag_1: -0.1060\n","insulinSensitivityFactor_lag_2: -0.1243\n","insulinSensitivityFactor_lag_3: 0.0876\n","insulinSensitivityFactor_lag_4: 0.0440\n","insulinSensitivityFactor_lag_5: 0.0563\n","insulinSensitivityFactor_lag_6: 0.0514\n","insulinSensitivityFactor_lag_7: 0.0528\n","insulinSensitivityFactor_lag_8: 0.0642\n","insulinSensitivityFactor_lag_9: 0.0705\n","insulinSensitivityFactor_lag_10: 0.0700\n","insulinSensitivityFactor_lag_11: 0.0612\n","insulinSensitivityFactor_lag_12: 0.0561\n","targetBloodGlucose_lag_1: 0.0689\n","targetBloodGlucose_lag_2: 0.0383\n","targetBloodGlucose_lag_3: -2.4191\n","targetBloodGlucose_lag_4: -0.2142\n","targetBloodGlucose_lag_5: 1.7948\n","targetBloodGlucose_lag_6: 1.5889\n","targetBloodGlucose_lag_7: 2.1961\n","targetBloodGlucose_lag_8: 2.7726\n","targetBloodGlucose_lag_9: 0.6000\n","targetBloodGlucose_lag_10: -0.5191\n","targetBloodGlucose_lag_11: 0.4087\n","targetBloodGlucose_lag_12: 1.8910\n","insulinOnBoard_lag_1: 1.2714\n","insulinOnBoard_lag_2: 1.7477\n","Intercept: 24.1477\n","Time step 6 (predicting 30 minutes ahead) - ARX RMSE: 24.2616\n","Linear Regression Coefficients (ARX Model):\n","lag_1: 1.6550\n","lag_2: -0.3603\n","lag_3: -0.2187\n","lag_4: -0.1003\n","lag_5: -0.0290\n","lag_6: -0.0494\n","lag_7: -0.0384\n","lag_8: -0.0171\n","lag_9: -0.0116\n","lag_10: -0.0016\n","lag_11: 0.0131\n","lag_12: -0.0475\n","normal: 3.3378\n","carbInput: 3.0552\n","insulinCarbRatio: 2.8173\n","bgInput: 2.4830\n","recommended.carb: 2.0889\n","recommended.net: 1.7982\n","recommended.correction: 1.5501\n","insulinSensitivityFactor: 1.3217\n","targetBloodGlucose: 1.1884\n","insulinOnBoard: 0.9114\n","normal_lag_1: 0.9431\n","normal_lag_2: 0.8528\n","normal_lag_3: -0.4423\n","normal_lag_4: -0.4845\n","normal_lag_5: -0.4713\n","normal_lag_6: -0.7270\n","normal_lag_7: -0.8899\n","normal_lag_8: -0.8930\n","normal_lag_9: -0.6697\n","normal_lag_10: -0.6436\n","normal_lag_11: -0.1688\n","normal_lag_12: 0.1189\n","carbInput_lag_1: 0.1972\n","carbInput_lag_2: 0.4641\n","carbInput_lag_3: 0.9973\n","carbInput_lag_4: 1.2024\n","carbInput_lag_5: 0.5779\n","carbInput_lag_6: 0.4909\n","carbInput_lag_7: 0.3269\n","carbInput_lag_8: 0.3462\n","carbInput_lag_9: 0.2222\n","carbInput_lag_10: 0.2187\n","carbInput_lag_11: 0.3369\n","carbInput_lag_12: 0.5519\n","insulinCarbRatio_lag_1: 0.5605\n","insulinCarbRatio_lag_2: 1.1865\n","insulinCarbRatio_lag_3: -0.0580\n","insulinCarbRatio_lag_4: -0.0556\n","insulinCarbRatio_lag_5: -0.0479\n","insulinCarbRatio_lag_6: -0.0289\n","insulinCarbRatio_lag_7: -0.0231\n","insulinCarbRatio_lag_8: -0.0269\n","insulinCarbRatio_lag_9: -0.0310\n","insulinCarbRatio_lag_10: -0.0511\n","insulinCarbRatio_lag_11: -0.0610\n","insulinCarbRatio_lag_12: -0.0587\n","bgInput_lag_1: -0.0679\n","bgInput_lag_2: -0.0633\n","bgInput_lag_3: 9.9251\n","bgInput_lag_4: 7.4783\n","bgInput_lag_5: 4.9882\n","bgInput_lag_6: 6.1320\n","bgInput_lag_7: 6.9620\n","bgInput_lag_8: 5.3886\n","bgInput_lag_9: 6.5800\n","bgInput_lag_10: 8.8906\n","bgInput_lag_11: 3.2093\n","bgInput_lag_12: -2.1885\n","recommended.carb_lag_1: -3.0686\n","recommended.carb_lag_2: -6.4745\n","recommended.carb_lag_3: -9.4276\n","recommended.carb_lag_4: -6.4827\n","recommended.carb_lag_5: -3.6106\n","recommended.carb_lag_6: -2.9989\n","recommended.carb_lag_7: -2.1071\n","recommended.carb_lag_8: -0.9181\n","recommended.carb_lag_9: -4.0757\n","recommended.carb_lag_10: -6.9170\n","recommended.carb_lag_11: -4.7007\n","recommended.carb_lag_12: -1.1539\n","recommended.net_lag_1: -0.3919\n","recommended.net_lag_2: 0.8345\n","recommended.net_lag_3: 5.9397\n","recommended.net_lag_4: 3.1693\n","recommended.net_lag_5: -0.5204\n","recommended.net_lag_6: -2.2223\n","recommended.net_lag_7: -2.3563\n","recommended.net_lag_8: -2.9790\n","recommended.net_lag_9: 0.6421\n","recommended.net_lag_10: 5.0793\n","recommended.net_lag_11: 3.8859\n","recommended.net_lag_12: 0.8639\n","recommended.correction_lag_1: 1.2047\n","recommended.correction_lag_2: 0.6148\n","recommended.correction_lag_3: -0.1500\n","recommended.correction_lag_4: -0.1349\n","recommended.correction_lag_5: -0.1295\n","recommended.correction_lag_6: -0.1624\n","recommended.correction_lag_7: -0.1812\n","recommended.correction_lag_8: -0.1895\n","recommended.correction_lag_9: -0.1745\n","recommended.correction_lag_10: -0.2001\n","recommended.correction_lag_11: -0.1895\n","recommended.correction_lag_12: -0.1737\n","insulinSensitivityFactor_lag_1: -0.1931\n","insulinSensitivityFactor_lag_2: -0.1859\n","insulinSensitivityFactor_lag_3: 0.1157\n","insulinSensitivityFactor_lag_4: 0.0877\n","insulinSensitivityFactor_lag_5: 0.1059\n","insulinSensitivityFactor_lag_6: 0.1123\n","insulinSensitivityFactor_lag_7: 0.0910\n","insulinSensitivityFactor_lag_8: 0.0816\n","insulinSensitivityFactor_lag_9: 0.0828\n","insulinSensitivityFactor_lag_10: 0.0925\n","insulinSensitivityFactor_lag_11: 0.0847\n","insulinSensitivityFactor_lag_12: 0.0739\n","targetBloodGlucose_lag_1: 0.0677\n","targetBloodGlucose_lag_2: 0.0383\n","targetBloodGlucose_lag_3: -3.2939\n","targetBloodGlucose_lag_4: -0.6623\n","targetBloodGlucose_lag_5: 2.2929\n","targetBloodGlucose_lag_6: 2.6502\n","targetBloodGlucose_lag_7: 2.6778\n","targetBloodGlucose_lag_8: 4.1425\n","targetBloodGlucose_lag_9: 1.5453\n","targetBloodGlucose_lag_10: -1.0922\n","targetBloodGlucose_lag_11: 0.4479\n","targetBloodGlucose_lag_12: 3.1919\n","insulinOnBoard_lag_1: 4.0650\n","insulinOnBoard_lag_2: 4.1612\n","Intercept: 36.7378\n","Time step 9 (predicting 45 minutes ahead) - ARX RMSE: 30.9784\n","Linear Regression Coefficients (ARX Model):\n","lag_1: 1.5943\n","lag_2: -0.3597\n","lag_3: -0.2170\n","lag_4: -0.1076\n","lag_5: -0.0296\n","lag_6: -0.0498\n","lag_7: -0.0331\n","lag_8: -0.0161\n","lag_9: -0.0061\n","lag_10: -0.0006\n","lag_11: 0.0128\n","lag_12: -0.0629\n","normal: 3.7624\n","carbInput: 3.5762\n","insulinCarbRatio: 3.3655\n","bgInput: 2.9166\n","recommended.carb: 2.5337\n","recommended.net: 2.1318\n","recommended.correction: 1.8375\n","insulinSensitivityFactor: 1.4180\n","targetBloodGlucose: 1.2020\n","insulinOnBoard: 0.8062\n","normal_lag_1: 0.9309\n","normal_lag_2: 0.9514\n","normal_lag_3: -0.8022\n","normal_lag_4: -0.8063\n","normal_lag_5: -0.7057\n","normal_lag_6: -0.6265\n","normal_lag_7: -0.6444\n","normal_lag_8: -0.5759\n","normal_lag_9: -0.3335\n","normal_lag_10: -0.3279\n","normal_lag_11: 0.2082\n","normal_lag_12: 0.5438\n","carbInput_lag_1: 0.7233\n","carbInput_lag_2: 0.9852\n","carbInput_lag_3: 0.5707\n","carbInput_lag_4: 0.9844\n","carbInput_lag_5: 0.6755\n","carbInput_lag_6: 0.6499\n","carbInput_lag_7: 0.6421\n","carbInput_lag_8: 0.7785\n","carbInput_lag_9: 0.7648\n","carbInput_lag_10: 0.8628\n","carbInput_lag_11: 0.9542\n","carbInput_lag_12: 1.1969\n","insulinCarbRatio_lag_1: 1.0245\n","insulinCarbRatio_lag_2: 1.3079\n","insulinCarbRatio_lag_3: -0.0769\n","insulinCarbRatio_lag_4: -0.0614\n","insulinCarbRatio_lag_5: -0.0553\n","insulinCarbRatio_lag_6: -0.0427\n","insulinCarbRatio_lag_7: -0.0468\n","insulinCarbRatio_lag_8: -0.0510\n","insulinCarbRatio_lag_9: -0.0531\n","insulinCarbRatio_lag_10: -0.0763\n","insulinCarbRatio_lag_11: -0.0899\n","insulinCarbRatio_lag_12: -0.0990\n","bgInput_lag_1: -0.1124\n","bgInput_lag_2: -0.1159\n","bgInput_lag_3: 12.5979\n","bgInput_lag_4: 10.3705\n","bgInput_lag_5: 6.2319\n","bgInput_lag_6: 5.7267\n","bgInput_lag_7: 6.6870\n","bgInput_lag_8: 3.8304\n","bgInput_lag_9: 2.9713\n","bgInput_lag_10: 3.6461\n","bgInput_lag_11: -2.2168\n","bgInput_lag_12: -7.0781\n","recommended.carb_lag_1: -9.1696\n","recommended.carb_lag_2: -11.9380\n","recommended.carb_lag_3: -10.0910\n","recommended.carb_lag_4: -7.7842\n","recommended.carb_lag_5: -4.0330\n","recommended.carb_lag_6: -4.1635\n","recommended.carb_lag_7: -4.8328\n","recommended.carb_lag_8: -2.7734\n","recommended.carb_lag_9: -3.6700\n","recommended.carb_lag_10: -4.2608\n","recommended.carb_lag_11: -2.2625\n","recommended.carb_lag_12: 0.4848\n","recommended.net_lag_1: 1.8088\n","recommended.net_lag_2: 2.6013\n","recommended.net_lag_3: 5.5952\n","recommended.net_lag_4: 2.9083\n","recommended.net_lag_5: -1.2060\n","recommended.net_lag_6: -1.7608\n","recommended.net_lag_7: 0.2696\n","recommended.net_lag_8: -0.8076\n","recommended.net_lag_9: 1.0466\n","recommended.net_lag_10: 4.1120\n","recommended.net_lag_11: 3.3487\n","recommended.net_lag_12: 1.7648\n","recommended.correction_lag_1: 1.3923\n","recommended.correction_lag_2: 1.1294\n","recommended.correction_lag_3: -0.2192\n","recommended.correction_lag_4: -0.1913\n","recommended.correction_lag_5: -0.1779\n","recommended.correction_lag_6: -0.1951\n","recommended.correction_lag_7: -0.2257\n","recommended.correction_lag_8: -0.2646\n","recommended.correction_lag_9: -0.2691\n","recommended.correction_lag_10: -0.2856\n","recommended.correction_lag_11: -0.2467\n","recommended.correction_lag_12: -0.1907\n","insulinSensitivityFactor_lag_1: -0.1916\n","insulinSensitivityFactor_lag_2: -0.1669\n","insulinSensitivityFactor_lag_3: 0.1761\n","insulinSensitivityFactor_lag_4: 0.1267\n","insulinSensitivityFactor_lag_5: 0.1231\n","insulinSensitivityFactor_lag_6: 0.1254\n","insulinSensitivityFactor_lag_7: 0.1152\n","insulinSensitivityFactor_lag_8: 0.1076\n","insulinSensitivityFactor_lag_9: 0.1021\n","insulinSensitivityFactor_lag_10: 0.0917\n","insulinSensitivityFactor_lag_11: 0.0832\n","insulinSensitivityFactor_lag_12: 0.0592\n","targetBloodGlucose_lag_1: 0.0570\n","targetBloodGlucose_lag_2: 0.0404\n","targetBloodGlucose_lag_3: -2.1273\n","targetBloodGlucose_lag_4: 0.0087\n","targetBloodGlucose_lag_5: 3.6028\n","targetBloodGlucose_lag_6: 3.5509\n","targetBloodGlucose_lag_7: 2.0729\n","targetBloodGlucose_lag_8: 4.0153\n","targetBloodGlucose_lag_9: 2.7467\n","targetBloodGlucose_lag_10: 1.7323\n","targetBloodGlucose_lag_11: 2.8060\n","targetBloodGlucose_lag_12: 5.1801\n","insulinOnBoard_lag_1: 6.5267\n","insulinOnBoard_lag_2: 6.7122\n","Intercept: 49.3254\n","Time step 12 (predicting 60 minutes ahead) - ARX RMSE: 36.6605\n"]}]},{"cell_type":"markdown","source":["Recursive AR Model"],"metadata":{"id":"il6JtroVCShw"}},{"cell_type":"code","source":["# Recursive forecasting function for the AR model\n","def recursive_forecast_ar_model(data, model, num_steps):\n","    # Initialize a list to store predictions\n","    predictions = []\n","\n","    # Get the last 'num_lags' lag values from the data for initial input\n","    last_known_data = data[[f'lag_{i}' for i in range(1, num_lags + 1)]].iloc[-1].values\n","\n","    # Generate recursive predictions\n","    for _ in range(num_steps):\n","        # Reshape last known data to fit model input format\n","        next_input = last_known_data.reshape(1, -1)\n","\n","        # Predict the next step\n","        next_pred = model.predict(next_input)[0]\n","        predictions.append(next_pred)\n","\n","        # Update the input data by adding the new prediction and dropping the oldest value\n","        last_known_data = np.roll(last_known_data, -1)  # Shift values left\n","        last_known_data[-1] = next_pred  # Add new prediction as the latest lag\n","\n","    return predictions"],"metadata":{"id":"HkIlwTAcIGPg","executionInfo":{"status":"ok","timestamp":1734032918553,"user_tz":300,"elapsed":12,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Function to train the AR model on 1-step-ahead predictions\n","def train_single_step_ar_model(data):\n","    # Prepare inputs (X) and target (y) for single step\n","    X = data[[f'lag_{i}' for i in range(1, num_lags + 1)]].values\n","    y = data['mg/dl'].shift(-1).dropna().values\n","    X = X[:len(y)]  # Align lengths\n","\n","    # Split into train/test\n","    X_train, X_test = X[:train_size], X[train_size:]\n","    y_train, y_test = y[:train_size], y[train_size:]\n","\n","    # Train the model\n","    model = LinearRegression()\n","    model.fit(X_train, y_train)\n","\n","    # Make predictions on the test set (1-step-ahead for evaluation)\n","    y_pred = model.predict(X_test)\n","\n","    # Calculate performance metric (RMSE)\n","    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","\n","    return model, rmse"],"metadata":{"id":"sHM5bCFsIHft","executionInfo":{"status":"ok","timestamp":1734032918554,"user_tz":300,"elapsed":11,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Train the single-step AR model and evaluate\n","single_step_model, single_step_rmse = train_single_step_ar_model(cgm_data)\n","print(f\"Single-step prediction model - RMSE: {single_step_rmse:.4f}\")\n","\n","# Perform recursive forecasting for different time steps\n","future_steps = [3, 6, 9, 12]  # 15, 30, 45, 60 minutes ahead\n","recursive_results = {}\n","\n","for step in future_steps:\n","    # Recursive prediction\n","    predictions = recursive_forecast_ar_model(cgm_data, single_step_model, step)\n","    recursive_results[f'{step*5} min ahead'] = predictions\n","    print(f\"Recursive prediction for {step*5} minutes ahead: {predictions}\")"],"metadata":{"id":"Ji0Xv3QuIPyE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734032918861,"user_tz":300,"elapsed":317,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}},"outputId":"2a92d19a-dd6b-43d4-8232-ee5520f1f668"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Single-step prediction model - RMSE: 9.9262\n","Recursive prediction for 15 minutes ahead: [337.5839078713668, 354.65831259882157, 379.013804851935]\n","Recursive prediction for 30 minutes ahead: [337.5839078713668, 354.65831259882157, 379.013804851935, 382.7365251466214, 350.7346734631458, 313.84221206502366]\n","Recursive prediction for 45 minutes ahead: [337.5839078713668, 354.65831259882157, 379.013804851935, 382.7365251466214, 350.7346734631458, 313.84221206502366, 305.24463075609754, 257.5197922044743, 262.1233244608659]\n","Recursive prediction for 60 minutes ahead: [337.5839078713668, 354.65831259882157, 379.013804851935, 382.7365251466214, 350.7346734631458, 313.84221206502366, 305.24463075609754, 257.5197922044743, 262.1233244608659, 308.24861977916646, 351.4782246485033, 355.6336226734991]\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import mean_squared_error\n","\n","# Function to calculate RMSE for each recursive forecast\n","def calculate_recursive_rmse(data, model, num_steps):\n","    # Initialize list to store RMSE values\n","    rmse_values = {}\n","\n","    # Iterate through each time step to calculate RMSE\n","    for step in num_steps:\n","        # Get the recursive predictions for the current step\n","        predictions = recursive_forecast_ar_model(data, model, step)\n","\n","        # Get the actual values corresponding to this step\n","        actual_values = data['mg/dl'].shift(-step).dropna().values[:len(predictions)]\n","\n","        # Calculate RMSE for this time step\n","        rmse = np.sqrt(mean_squared_error(actual_values, predictions))\n","        rmse_values[f'{step*5} min ahead'] = rmse\n","        print(f\"RMSE for recursive forecast {step*5} minutes ahead: {rmse:.4f}\")\n","\n","    return rmse_values\n","\n","# Calculate RMSE for recursive forecasts on the test set\n","recursive_rmse = calculate_recursive_rmse(cgm_data[train_size:], single_step_model, future_steps)\n"],"metadata":{"id":"LlBYNsjVInan","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734032918862,"user_tz":300,"elapsed":17,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}},"outputId":"68abfee6-1ea6-4cea-e36a-6d5cb28ae340"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["RMSE for recursive forecast 15 minutes ahead: 89.0505\n","RMSE for recursive forecast 30 minutes ahead: 71.9594\n","RMSE for recursive forecast 45 minutes ahead: 54.6455\n","RMSE for recursive forecast 60 minutes ahead: 46.4694\n"]}]},{"cell_type":"markdown","source":["LASSO Regression"],"metadata":{"id":"NkjsoBRYIvw9"}},{"cell_type":"code","source":["from sklearn.linear_model import Lasso\n","\n","# Function to train and evaluate a Lasso regression model for a specified prediction step\n","def train_lasso_model(data, target_step, alpha=0.1, max_iter=5000):\n","    # Prepare inputs (X) and target (y)\n","    X = data[[f'lag_{i}' for i in range(1, num_lags + 1)]].values\n","    y = data['mg/dl'].shift(-target_step).dropna().values\n","    X = X[:len(y)]  # Align lengths\n","\n","    # Split into train/test\n","    X_train, X_test = X[:train_size], X[train_size:]\n","    y_train, y_test = y[:train_size], y[train_size:]\n","\n","    # Train the Lasso model with specified alpha (regularization strength)\n","    lasso_model = Lasso(alpha=alpha, max_iter=max_iter)\n","    lasso_model.fit(X_train, y_train)\n","\n","    # Make predictions\n","    y_pred = lasso_model.predict(X_test)\n","\n","    # Calculate performance metric (RMSE)\n","    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","\n","    return lasso_model, rmse"],"metadata":{"id":"W0vXtL8pM4Op","executionInfo":{"status":"ok","timestamp":1734032918862,"user_tz":300,"elapsed":10,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Train and evaluate Lasso models for different time steps\n","lasso_results = {}\n","for step in time_steps:\n","    model, rmse = train_lasso_model(cgm_data, step, alpha=0.1, max_iter=5000)\n","    lasso_results[f'{step*5} min ahead'] = {'Model': model, 'RMSE': rmse}\n","    print(f\"Lasso regression for {step*5} minutes ahead - RMSE: {rmse:.4f}\")"],"metadata":{"id":"btYD6roIM5XK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734032977452,"user_tz":300,"elapsed":58597,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}},"outputId":"049f8c1a-962a-4b25-9bb5-f4af323bbb7e"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Lasso regression for 15 minutes ahead - RMSE: 16.4987\n","Lasso regression for 30 minutes ahead - RMSE: 24.4686\n","Lasso regression for 45 minutes ahead - RMSE: 31.1751\n","Lasso regression for 60 minutes ahead - RMSE: 36.8410\n"]}]},{"cell_type":"markdown","source":["Ridge Regression"],"metadata":{"id":"3jrB_xynPg3_"}},{"cell_type":"code","source":["from sklearn.linear_model import Ridge\n","\n","# Function to train and evaluate a Ridge regression model for a specified prediction step\n","def train_ridge_model(data, target_step, alpha=1.0):\n","    # Prepare inputs (X) and target (y)\n","    X = data[[f'lag_{i}' for i in range(1, num_lags + 1)]].values\n","    y = data['mg/dl'].shift(-target_step).dropna().values\n","    X = X[:len(y)]  # Align lengths\n","\n","    # Split into train/test\n","    X_train, X_test = X[:train_size], X[train_size:]\n","    y_train, y_test = y[:train_size], y[train_size:]\n","\n","    # Train the Ridge model with specified alpha (regularization strength)\n","    ridge_model = Ridge(alpha=alpha)\n","    ridge_model.fit(X_train, y_train)\n","\n","    # Make predictions\n","    y_pred = ridge_model.predict(X_test)\n","\n","    # Calculate performance metric (RMSE)\n","    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","\n","    return ridge_model, rmse\n","\n","# Train and evaluate Ridge models for different time steps\n","ridge_results = {}\n","alpha_value = 1.0  # Adjust alpha as needed for regularization strength\n","for step in time_steps:\n","    model, rmse = train_ridge_model(cgm_data, step, alpha=alpha_value)\n","    ridge_results[f'{step*5} min ahead'] = {'Model': model, 'RMSE': rmse}\n","    print(f\"Ridge regression for {step*5} minutes ahead - RMSE: {rmse:.4f}\")\n"],"metadata":{"id":"GyVdNSkKSL5j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734032977781,"user_tz":300,"elapsed":367,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}},"outputId":"ae790bfe-3315-4d76-fa6e-91b1be2d0ee8"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Ridge regression for 15 minutes ahead - RMSE: 16.4981\n","Ridge regression for 30 minutes ahead - RMSE: 24.4678\n","Ridge regression for 45 minutes ahead - RMSE: 31.1743\n","Ridge regression for 60 minutes ahead - RMSE: 36.8401\n"]}]},{"cell_type":"markdown","source":["Elastic Net Regression"],"metadata":{"id":"l7xmEKZHYzVa"}},{"cell_type":"code","source":["from sklearn.linear_model import ElasticNet\n","\n","# Function to train and evaluate ElasticNet model\n","def train_elastic_net_model(data, target_step, alpha=1.0, l1_ratio=0.5):\n","    # Prepare inputs (X) and target (y)\n","    X = data[[f'lag_{i}' for i in range(1, num_lags + 1)]].values\n","    y = data['mg/dl'].shift(-target_step).dropna().values\n","    X = X[:len(y)]  # Align lengths\n","\n","    # Split into train/test\n","    X_train, X_test = X[:train_size], X[train_size:]\n","    y_train, y_test = y[:train_size], y[train_size:]\n","\n","    # Train the ElasticNet model\n","    elastic_net_model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n","    elastic_net_model.fit(X_train, y_train)\n","\n","    # Make predictions\n","    y_pred = elastic_net_model.predict(X_test)\n","\n","    # Calculate performance metric (RMSE)\n","    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","\n","    return elastic_net_model, rmse\n","\n","# Train and evaluate ElasticNet models for different time steps\n","elastic_net_results = {}\n","alpha_value = 1.0  # Regularization strength (larger values => more regularization)\n","l1_ratio_value = 0.5  # Mix ratio between Lasso (L1) and Ridge (L2) regularization\n","for step in time_steps:\n","    model, rmse = train_elastic_net_model(cgm_data, step, alpha=alpha_value, l1_ratio=l1_ratio_value)\n","    elastic_net_results[f'{step*5} min ahead'] = {'Model': model, 'RMSE': rmse}\n","    print(f\"ElasticNet for {step*5} minutes ahead - RMSE: {rmse:.4f}\")\n"],"metadata":{"id":"xelNG6-fY-hH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734033010010,"user_tz":300,"elapsed":32238,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}},"outputId":"7e9f43e4-4a03-41f6-8071-0143375a5c8f"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["ElasticNet for 15 minutes ahead - RMSE: 16.5064\n","ElasticNet for 30 minutes ahead - RMSE: 24.4763\n","ElasticNet for 45 minutes ahead - RMSE: 31.1826\n","ElasticNet for 60 minutes ahead - RMSE: 36.8497\n"]}]},{"cell_type":"markdown","source":["Huber"],"metadata":{"id":"dElBbo6IZGGM"}},{"cell_type":"code","source":["from sklearn.linear_model import HuberRegressor\n","\n","# Function to train and evaluate Huber regression model\n","def train_huber_model(data, target_step, epsilon=1.35):\n","    # Prepare inputs (X) and target (y)\n","    X = data[[f'lag_{i}' for i in range(1, num_lags + 1)]].values\n","    y = data['mg/dl'].shift(-target_step).dropna().values\n","    X = X[:len(y)]  # Align lengths\n","\n","    # Split into train/test\n","    X_train, X_test = X[:train_size], X[train_size:]\n","    y_train, y_test = y[:train_size], y[train_size:]\n","\n","    # Train the Huber regression model\n","    huber_model = HuberRegressor(epsilon=epsilon, max_iter=1000)\n","    huber_model.fit(X_train, y_train)\n","\n","    # Make predictions\n","    y_pred = huber_model.predict(X_test)\n","\n","    # Calculate performance metric (RMSE)\n","    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","\n","    return huber_model, rmse\n","\n","# Train and evaluate Huber models for different time steps\n","huber_results = {}\n","epsilon_value = 1.35  # Huber loss function parameter (controls the threshold between quadratic and linear loss)\n","for step in time_steps:\n","    model, rmse = train_huber_model(cgm_data, step, epsilon=epsilon_value)\n","    huber_results[f'{step*5} min ahead'] = {'Model': model, 'RMSE': rmse}\n","    print(f\"Huber for {step*5} minutes ahead - RMSE: {rmse:.4f}\")\n"],"metadata":{"id":"JaMt0glzZLSK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734033144744,"user_tz":300,"elapsed":134743,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}},"outputId":"8f1756b7-387c-4c8f-bb87-e2dfb98da739"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Huber for 15 minutes ahead - RMSE: 16.6951\n","Huber for 30 minutes ahead - RMSE: 24.5882\n","Huber for 45 minutes ahead - RMSE: 31.2031\n","Huber for 60 minutes ahead - RMSE: 36.7885\n"]}]},{"cell_type":"markdown","source":["Random Forest"],"metadata":{"id":"_GyZIr2Ca_Mo"}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_squared_error\n","\n","# Function to train and evaluate Random Forest model\n","def train_rf_model(data, target_step, n_estimators=100, max_depth=None, random_state=42):\n","    # Prepare inputs (X) and target (y)\n","    X = data[[f'lag_{i}' for i in range(1, num_lags + 1)]].values\n","    y = data['mg/dl'].shift(-target_step).dropna().values\n","    X = X[:len(y)]  # Align lengths\n","\n","    # Split into train/test\n","    X_train, X_test = X[:train_size], X[train_size:]\n","    y_train, y_test = y[:train_size], y[train_size:]\n","\n","    # Train the Random Forest model\n","    rf_model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=random_state)\n","    rf_model.fit(X_train, y_train)\n","\n","    # Make predictions\n","    y_pred = rf_model.predict(X_test)\n","\n","    # Calculate performance metric (RMSE)\n","    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","\n","    return rf_model, rmse\n","\n","# Train and evaluate Random Forest models for different time steps\n","rf_results = {}\n","for step in time_steps:\n","    model, rmse = train_rf_model(cgm_data, step, n_estimators=100, max_depth=10)\n","    rf_results[f'{step*5} min ahead'] = {'Model': model, 'RMSE': rmse}\n","    print(f\"Random Forest for {step*5} minutes ahead - RMSE: {rmse:.4f}\")\n"],"metadata":{"id":"ccFkUnHchZzE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734033790462,"user_tz":300,"elapsed":645764,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}},"outputId":"36742612-e13f-4736-ac03-cf902712961e"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Random Forest for 15 minutes ahead - RMSE: 15.9138\n","Random Forest for 30 minutes ahead - RMSE: 23.6204\n","Random Forest for 45 minutes ahead - RMSE: 30.2032\n","Random Forest for 60 minutes ahead - RMSE: 35.7986\n"]}]},{"cell_type":"markdown","source":["XGBoost"],"metadata":{"id":"opeXoGyzbAGT"}},{"cell_type":"code","source":["import xgboost as xgb\n","from sklearn.metrics import mean_squared_error\n","\n","# Function to train and evaluate XGBoost model\n","def train_xgb_model(data, target_step, num_boost_round=100, learning_rate=0.1, max_depth=30, random_state=42):\n","    # Prepare inputs (X) and target (y)\n","    X = data[[f'lag_{i}' for i in range(1, num_lags + 1)]].values\n","    y = data['mg/dl'].shift(-target_step).dropna().values\n","    X = X[:len(y)]  # Align lengths\n","\n","    # Split into train/test\n","    X_train, X_test = X[:train_size], X[train_size:]\n","    y_train, y_test = y[:train_size], y[train_size:]\n","\n","    # Create DMatrix for XGBoost\n","    dtrain = xgb.DMatrix(X_train, label=y_train)\n","    dtest = xgb.DMatrix(X_test, label=y_test)\n","\n","    # Set parameters for XGBoost\n","    params = {\n","        'objective': 'reg:squarederror',  # Regression task (squared error loss)\n","        'eval_metric': 'rmse',            # Metric to evaluate model\n","        'max_depth': max_depth,           # Depth of the trees\n","        'learning_rate': learning_rate,  # Step size shrinkage\n","        'random_state': random_state,    # For reproducibility\n","    }\n","\n","    # Train the XGBoost model\n","    model = xgb.train(params, dtrain, num_boost_round=num_boost_round)\n","\n","    # Make predictions\n","    y_pred = model.predict(dtest)\n","\n","    # Calculate performance metric (RMSE)\n","    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","\n","    return model, rmse\n","\n","# Train and evaluate XGBoost models for different time steps\n","xgb_results = {}\n","for step in time_steps:\n","    model, rmse = train_xgb_model(cgm_data, step, num_boost_round=100, learning_rate=0.1, max_depth=10)\n","    xgb_results[f'{step*5} min ahead'] = {'Model': model, 'RMSE': rmse}\n","    print(f\"XGBoost for {step*5} minutes ahead - RMSE: {rmse:.4f}\")\n"],"metadata":{"id":"qFksTsoXoejo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734033824278,"user_tz":300,"elapsed":33827,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}},"outputId":"e92ba8d5-e6d4-46d9-9dbe-27d0397912a7"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["XGBoost for 15 minutes ahead - RMSE: 15.9221\n","XGBoost for 30 minutes ahead - RMSE: 23.6233\n","XGBoost for 45 minutes ahead - RMSE: 30.2112\n","XGBoost for 60 minutes ahead - RMSE: 35.7944\n"]}]},{"cell_type":"code","source":["import xgboost as xgb\n","from sklearn.metrics import mean_squared_error\n","import numpy as np\n","\n","# Function to train and evaluate XGBoost model with ARX features\n","def train_xgb_arx_model(data, target_step, num_boost_round=100, learning_rate=0.1, max_depth=10, random_state=42):\n","    # Prepare inputs (X) and target (y)\n","    # Use all lagged features (CGM + Bolus variables)\n","    feature_columns = [col for col in data.columns if col.startswith('lag_') or '_lag_' in col]\n","    X = data[feature_columns].values\n","    y = data['mg/dl'].shift(-target_step).dropna().values\n","    X = X[:len(y)]  # Align lengths\n","\n","    # Split into train/test\n","    X_train, X_test = X[:train_size], X[train_size:]\n","    y_train, y_test = y[:train_size], y[train_size:]\n","\n","    # Create DMatrix for XGBoost\n","    dtrain = xgb.DMatrix(X_train, label=y_train)\n","    dtest = xgb.DMatrix(X_test, label=y_test)\n","\n","    # Set parameters for XGBoost\n","    params = {\n","        'objective': 'reg:squarederror',  # Regression task (squared error loss)\n","        'eval_metric': 'rmse',            # Metric to evaluate model\n","        'max_depth': max_depth,           # Depth of the trees\n","        'learning_rate': learning_rate,   # Step size shrinkage\n","        'random_state': random_state,     # For reproducibility\n","    }\n","\n","    # Train the XGBoost model\n","    model = xgb.train(params, dtrain, num_boost_round=num_boost_round)\n","\n","    # Make predictions\n","    y_pred = model.predict(dtest)\n","\n","    # Calculate performance metric (RMSE)\n","    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","\n","    return model, rmse\n","\n","# Train and evaluate XGBoost models for different time steps\n","xgb_arx_results = {}\n","for step in time_steps:\n","    model, rmse = train_xgb_arx_model(merged_data, step, num_boost_round=100, learning_rate=0.1, max_depth=10)\n","    xgb_arx_results[f'{step*5} min ahead'] = {'Model': model, 'RMSE': rmse}\n","    print(f\"XGBoost (ARX) for {step*5} minutes ahead - RMSE: {rmse:.4f}\")"],"metadata":{"id":"4rX7CK7TBFPM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734033946874,"user_tz":300,"elapsed":122637,"user":{"displayName":"Aaron Dantzler","userId":"01397289172024144959"}},"outputId":"34263a2b-6830-4282-9b74-f2a4d31e6499"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["XGBoost (ARX) for 15 minutes ahead - RMSE: 15.8828\n","XGBoost (ARX) for 30 minutes ahead - RMSE: 23.4537\n","XGBoost (ARX) for 45 minutes ahead - RMSE: 30.0152\n","XGBoost (ARX) for 60 minutes ahead - RMSE: 35.7049\n"]}]}]}